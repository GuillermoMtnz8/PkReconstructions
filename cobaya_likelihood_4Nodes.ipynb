{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to be loaded\n",
    "import cobaya\n",
    "import camb\n",
    "import numpy as np\n",
    "import sympy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmological parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosmological constants\n",
    "c = 2.99792458E5;   HJPAS = 1/(c/100);\n",
    "\n",
    "#Parameteres that won't be sampled. Planck 2018-compatible\n",
    "gamma = 0.545; OmegakJPAS = 0; AsJPAS = 2.09052E-9; nsJPAS = 0.9626; tauJPAS = 0.06; mnuJPAS = 0.0; nmuJPAS = 3.046;\n",
    "\n",
    "#A set of the sampled cosmological parameters in the fiducial. Compatible with Planck 2018.\n",
    "hJPAS = 0.674\n",
    "OmegabJPASh2 = 0.02212\n",
    "OmegaCDMJPASh2 = 0.1206\n",
    "\n",
    "#Indirect cosmological parameters.\n",
    "H0JPAS = hJPAS*100\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2; OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiducial cosmology functions and constants (including FoG parameter sigmap)\n",
    "OmegamFid = 0.31417\n",
    "\n",
    "#At z=1.7 (first bin)\n",
    "EzFid = 2.6210003044889154\n",
    "XiFid = 3263.0797256936944\n",
    "DAFid = 1208.54804655322\n",
    "sigmapFid = 2.725068353464309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSS parameters for JPAS-like simulations\n",
    "DeltazJPAS = 0.00364236313918151\n",
    "fsky = 0.2575\n",
    "\n",
    "def bJPAS(z):\n",
    "    return 0.53+0.289*(1+z)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power law primordial power spectrum. Scale k must be in h units.\n",
    "def PrimordialPowerLaw(As,ns,k):\n",
    "    return As*(k/(0.05/hJPAS))**(ns-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power law primordial power spectrum without h units.\n",
    "def PrimordialPowerLawSinh(As,ns,k):\n",
    "    return As*(k/(0.05))**(ns-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k and z binning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays limits and steps.\n",
    "\n",
    "#K arrays in h units. \n",
    "kminKArrayComplete = 0.001;   kmaxKArrayComplete = 2.4900;  pasoKArrayComplete = 0.025;\n",
    "\n",
    "#k binning, complete and in a reduced scaleset\n",
    "KArrayComplete = np.exp(np.arange(math.log(kminKArrayComplete), math.log(kmaxKArrayComplete), pasoKArrayComplete) )\n",
    "KArray = KArrayComplete[range(121,246)]\n",
    "\n",
    "#k binning on lower and upper limits\n",
    "KArrayUpper = np.zeros(len(KArray)); KArrayLower = np.zeros(len(KArray));\n",
    "\n",
    "for i in range(0, len(KArray)-1):\n",
    "    KArrayUpper[i] = KArray[i] + (KArray[i+1]-KArray[i])/2;   KArrayLower[i] = KArray[i] - (KArray[i+1]-KArray[i])/2;\n",
    "\n",
    "KArrayUpper[-1] = KArrayUpper[-2];  KArrayLower[-1] = KArrayLower[-2];\n",
    "\n",
    "#z binning\n",
    "zmin = 1.7;   zmax = 2.9;   pasoz = 0.2;\n",
    "\n",
    "#Original one\n",
    "zaAntes = np.arange(zmin-0.1, zmax+pasoz/2, pasoz)\n",
    "\n",
    "#Including z=0\n",
    "zaAdicional = np.array([0])\n",
    "\n",
    "#Binning including all lower and upper z-bins limits\n",
    "zaConBines = np.arange(zmin-pasoz/2, zmax+0.01+pasoz/2, pasoz/2)\n",
    "\n",
    "#z binning with 0 and including z-bin limits\n",
    "za = np.concatenate((zaAdicional,zaConBines))\n",
    "\n",
    "#Positions of upper and lower limits of the z-bins in the za array\n",
    "positions_Upper = [3, 5, 7, 9, 11, 13, 15]\n",
    "positions_Lower = [1, 3, 5, 7, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(k) data and densities reading #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pkz', 'ndz', 'vs', 'tk'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a class to read the simulated data (Pk, densities) and, for doing checks,\n",
    "# the transfer function and the seed. The path must be specified as input.\n",
    "\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    Simulated_pk_filename = path_to_data+'SimulatedDataHighZChecked.dat'\n",
    "    Simulated_densities = path_to_data+'Densities_HighZ.dat'\n",
    "    Vector_Seed = path_to_data+'SeedVector.dat'\n",
    "\n",
    "    data['pkz'] = np.zeros((len(zaAntes), len(KArray)))\n",
    "    data['ndz'] = np.zeros(len(zaAntes))\n",
    "    data['vs'] = np.zeros(len(KArray))\n",
    "    data['tk'] = np.zeros(len(KArray))\n",
    "  \n",
    "    with open(Simulated_pk_filename) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['pkz'][0][i] = float(line[7])\n",
    "            data['tk'][i] = float(line[2])\n",
    "            \n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(zaAntes)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])\n",
    "\n",
    "    with open(Vector_Seed) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['vs'][i] = float(line[0])\n",
    "                  \n",
    "            \n",
    "    return data\n",
    "\n",
    "# Read data is converted in the dictionary 'data'\n",
    "\n",
    "#data = read_data('/gpfs/users/martinezg/Simulated_Data/')\n",
    "data = read_data('/Users/guillermo/Desktop/Simulated_Data/')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to interface with Cobaya #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The classes to interface with Cobaya are created.\n",
    "\n",
    "#A cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes are created\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class of the theory, with the PPS modification including the nodes\n",
    "\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Initialize self with the k-array.\n",
    "        self.ks = KArray\n",
    "\n",
    "    #Definition of knot parameters to be sampled.\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict):\n",
    "\n",
    "        #This part of the code orders the variables x.\n",
    "        \n",
    "        number_nodes = 4\n",
    "        number_nodes_red = number_nodes-2\n",
    "\n",
    "        megacube = np.zeros(number_nodes)\n",
    "        \n",
    "        megacube[0] = params_values_dict['x1']\n",
    "\n",
    "        megacube[1] = megacube[0] + (1 - megacube[0]) * (1 - (1 - params_values_dict['x2']) ** (1 /(number_nodes_red+1-(2-1)) ))\n",
    "        megacube[2] = megacube[1] + (1 - megacube[1]) * (1 - (1 - params_values_dict['x3']) ** (1 /(number_nodes_red+1-(3-1)) ))\n",
    "    \n",
    "        megacube[3] = params_values_dict['x4']\n",
    "\n",
    "        #Here we define que k-PPS nodes.\n",
    "\n",
    "        nodes_logk = [(np.log(KArray[-1])-np.log(KArray[0]) ) * megacube[0]  + np.log(KArray[0]), \n",
    "                      (np.log(KArray[-1])-np.log(KArray[0]) ) * megacube[1] + np.log(KArray[0]),\n",
    "                      (np.log(KArray[-1])-np.log(KArray[0]) ) * megacube[2] + np.log(KArray[0]),\n",
    "                      (np.log(KArray[-1])-np.log(KArray[0]) ) * megacube[3] + np.log(KArray[0])] \n",
    "        \n",
    "        nodes_logPPS = [params_values_dict['y1'], params_values_dict['y2'],params_values_dict['y3'],params_values_dict['y4']]\n",
    "\n",
    "\n",
    "\n",
    "        #nodes_k and nodes_PPS are linearly interpolated in log space. For outer values, we extraplote.\n",
    "        NodesInterpFunc_nodes = interp1d(nodes_logk, nodes_logPPS,\n",
    "        kind='linear', fill_value='extrapolate')\n",
    "\n",
    "        \n",
    "     #We construct a modified PPS(k) evaluated at our nodes and interpolated, evaluated at our k-array.\n",
    "        #The units must be without h in the limits of k\n",
    "        state['primordial_scalar_pk'] = {'kmin': KArray[0]*hJPAS, 'kmax': KArray[-1]*hJPAS,\n",
    "                                            'Pk': np.exp(NodesInterpFunc_nodes(np.log(KArray))), 'log_regular': True}\n",
    "        \n",
    "        \n",
    "    #Name the modified primordial power spectrum as 'primordial_scalar_pk' to be called in Cobaya.\n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "        \n",
    "    #Function that contains the parameters to be sampled.\n",
    "    def get_can_support_params(self):\n",
    "        return ['x1', 'x2', 'x3', 'x4', 'y1', 'y2','y3', 'y4']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class incorporating the model (monopole galaxy power spectrum) and the likelihood. \n",
    "\n",
    "class Pklike(Likelihood): \n",
    "\n",
    "    def initialize(self):  \n",
    "\n",
    "        #Path in wich the data are. We call read_data with this path.\n",
    "        #self.data = read_data('/gpfs/users/martinezg/Simulated_Data/')\n",
    "        self.data = read_data('/Users/guillermo/Desktop/Simulated_Data/')\n",
    "\n",
    "        #Grid of K\n",
    "        self.ks = KArray\n",
    "        \n",
    "        #Grid of z to be employed\n",
    "        self.z_win = za\n",
    "\n",
    "    \n",
    "    def get_requirements(self): #Cobaya functions that we might use.\n",
    "        \n",
    "        return {'omegam': None,                \n",
    "                'Pk_interpolator': {'z': self.z_win, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_win},\n",
    "                'angular_diameter_distance': {'z': self.z_win},\n",
    "                'Hubble': {'z': self.z_win, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_win}, 'fsigma8': {'z': self.z_win},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    "\n",
    "        \n",
    "    #Definition of the monopole. It will return:\n",
    "        #The monopole evaluated at z=1.7 and at the array of k\n",
    "        #The covariance evaluated at z=1.7 and at the array of k\n",
    "    \n",
    "    def monopole(self, **params_dic):\n",
    "        \n",
    "        #Options for print with enough decimal precision\n",
    "        np.set_printoptions(precision=24, suppress=True)\n",
    "\n",
    "        #CAMB results within Cobaya\n",
    "        resultsCobaya = self.provider.get_CAMBdata() \n",
    "        \n",
    "        #This is the modified primordial power spectrum P(k) evaluated at KArray.\n",
    "        primordialCobaya = self.provider.get_primordial_scalar_pk()\n",
    "        \n",
    "        #Construction of Pmatter(k) calling Cobaya.\n",
    "\n",
    "        pkCobaya = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False) \n",
    "        \n",
    "        # All functions and variables to compute the Kaiser model. It reads the cosmology from info (below)\n",
    "        \n",
    "        #Cosmological parameters from CAMB\n",
    "        Omegam = self.provider.get_param('omegam')  \n",
    "        \n",
    "        #Cosmological functions\n",
    "        Ez = np.sqrt( Omegam*(1+self.z_win)**3+(1-Omegam) ); \n",
    "        H = HJPAS * Ez\n",
    "        f = (Omegam*(1+self.z_win)**3*1/(Ez**2))**gamma\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_win)*hJPAS; #CAMB is called here\n",
    "        DA = Xi/(1+self.z_win);\n",
    "\n",
    "    \n",
    "        #A and R parameters withouth D(z) (thus calculating only Pm(1.7))\n",
    "        A = bJPAS(za)\n",
    "        R = f\n",
    "        \n",
    "        # Photometric factor\n",
    "        sigmar = DeltazJPAS*(1+self.z_win)/H\n",
    "\n",
    "        # Fingers of God effect at z = 1.7 in the fiducial\n",
    "        def FFog(mu,k):\n",
    "            return 1/(1+(f[2]*k*mu*sigmapFid)**2)\n",
    "\n",
    "        # AP effect\n",
    "        FactorAP = DAFid**2*EzFid/( DA[2]**2*EzFid )\n",
    "\n",
    "        def Q(mu):\n",
    "            return ((Ez[2]**2*Xi[2]**2*mu**2-EzFid**2*XiFid**2*(mu**2-1))**0.5/(EzFid*Xi[2]))\n",
    " \n",
    "        def muObs(mu):\n",
    "            return mu*Ez[2]/(EzFid*Q(mu))\n",
    "           \n",
    "        def kObs(mu,k):\n",
    "            return Q(mu)*k \n",
    "\n",
    "        #Galaxy Power spectrum (mu,k) with AP and FoG. The Pmatter of Cobaya must be evaluated at k without h units\n",
    "        def Pg(mu,k):\n",
    "            return FactorAP*FFog(muObs(mu),kObs(mu,k))*(A[2]+R[2]*muObs(mu)**2)**2 * (   (   pkCobaya.P(self.z_win[2],kObs(mu,k)*hJPAS)   )   ) *np.exp(-(k*mu*sigmar[2])**2)\n",
    "            \n",
    "\n",
    "        #Monopole galaxy power spectrum\n",
    "\n",
    "        #Trapezoid rule with 2000 steps for computing the Pmonopole(k)\n",
    "        def Pgmonopole(k):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 1/2 * integrate.trapz(Pg(mu, k), mu)\n",
    "\n",
    "        #We save the values at our KArray values\n",
    "        PgmonopoleValores = np.zeros(len(KArray))\n",
    "\n",
    "        for i in range(len(KArray)):\n",
    "            PgmonopoleValores[i] = Pgmonopole(KArray[i])\n",
    "\n",
    "        \n",
    "        #Covariance\n",
    "\n",
    "        #Angular distance for z upper and lower bins from CAMB\n",
    "        XiZaLower = self.provider.get_comoving_radial_distance(self.z_win[positions_Lower])*hJPAS\n",
    "        XiZaUpper = self.provider.get_comoving_radial_distance(self.z_win[positions_Upper])*hJPAS\n",
    "        \n",
    "        #Definition of the volume between redshift bins\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "   \n",
    "        #Number of modes. It depends of ksup and kinf corresponding to kupper y klower\n",
    "        def Nk(ksup,kinf):\n",
    "            return Vol[0] * (4*np.pi/3*(ksup**3-kinf**3))/((2*np.pi)**3)\n",
    "\n",
    "        #Nk evaluated for each of our k-bins. Densities are red from self.data['ndz].\n",
    "        NkEvaluado = np.zeros(len(self.ks))\n",
    "        for i in range(0, len(self.ks)):\n",
    "            NkEvaluado[i] = Nk(KArrayUpper[i],KArrayLower[i])  \n",
    "        \n",
    "        #Cov evaluated at our k array. Need to read the densities\n",
    "        CovEvaluado = 2 *(PgmonopoleValores + 1/self.data['ndz'][0])**2 / NkEvaluado\n",
    "\n",
    "        \n",
    "        #We return the value of the monopole at our k-array and of the Covariance Matrix at the same array\n",
    "        \n",
    "        return PgmonopoleValores, CovEvaluado\n",
    "\n",
    "\n",
    "    #Likelihood calculation\n",
    "    \n",
    "    def logp(self, **params_values):  \n",
    "        \n",
    "        \n",
    "        #For allocating the monopole values and cov valued\n",
    "        PMonopoleBineado = np.zeros((7, len(self.ks)))\n",
    "        CovBineado = np.zeros((7, len(self.ks)))\n",
    "\n",
    "        #PMonopoleBineado and CovBineado are equal to the values given by the self.monopole\n",
    "        PMonopoleBineado[0, :len(self.ks)],CovBineado[0, :len(self.ks)] = self.monopole(**params_values)\n",
    "        \n",
    "\n",
    "        #Construction of the likelihood like a Chi^2 with the log of determinant term\n",
    "        lnlike = 0.0\n",
    "        for i in range(len(KArray)):\n",
    "            lnlike = lnlike + ((PMonopoleBineado[0][i] - data['pkz'][0][i])**2 *1/CovBineado[0][i] + np.log(CovBineado[0][i]))\n",
    "\n",
    "        #We return - lnlinke/2\n",
    "        return -lnlike/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary given to Cobaya. We need to specify:\n",
    "    #Likelihood (class including the likelihood and the model).\n",
    "    #Theory class (in which we modify the PPS to have knots).\n",
    "    #Parameters (fixed and to be sampled).\n",
    "    #Sampler to be used and specifications.\n",
    "    #Output where save the output.\n",
    "    #Afitional options as debugind or resuming chains.\n",
    "\n",
    "\n",
    "info = {'debug': False,                        #Allow to debug\n",
    "        'likelihood': {'jpass': Pklike},       #Link likelihood with the previously defined clss\n",
    "        'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "                   'my_pk': NodesInPrimordialPk},      #We include the primordial Pk with nodes in the theory class\n",
    "       'params': {\n",
    "           \n",
    "        # Fixed cosmological parameters\n",
    "        'tau': tauJPAS, 'mnu': mnuJPAS, 'nnu': nmuJPAS,\n",
    "        'x1': 0.0,\n",
    "        'x4': 1.0,\n",
    "        'ombh2': OmegabJPASh2, 'omch2': OmegaCDMJPASh2, 'H0': H0JPAS,\n",
    "           \n",
    "        # Parameters of the nodes, with flat priors\n",
    "        'y1': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_1'},\n",
    "        'y2': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_2'},\n",
    "        'y3': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_3'},\n",
    "        'y4': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_3'},\n",
    "        'x2': {'prior': {'min': 0.0, 'max': 1.0}, 'ref': 0.5, 'latex': 'x_2'},\n",
    "        'x3': {'prior': {'min': 0.0, 'max': 1.0}, 'ref': 0.5, 'latex': 'x_2'}}, \n",
    "        \n",
    "        # Cosmological parameters to be sampled. Loc and scale are the mean value and the st deviation\n",
    "        #for a guassian prior\n",
    "        #'ombh2': {'prior': {'dist': 'norm', 'loc': OmegabJPASh2, 'scale': 0.00015}, 'latex': 'Omega_bh^2'},\n",
    "        #'omch2': {'prior': {'dist': 'norm', 'loc': OmegaCDMJPASh2, 'scale': 0.0012}, 'latex': 'Omega_ch^2'},\n",
    "        #'H0': {'prior': {'dist': 'norm', 'loc': H0JPAS, 'scale': 0.54}, 'latex': 'H_0'}},\n",
    "\n",
    "        \"sampler\": {\"polychord\":\n",
    "                        {\"nlive\": 175, \"precision_criterion\": 1e-3}\n",
    "                    }\n",
    "           }\n",
    "        \n",
    "#Path for output folder and name of the directory. First line: path for Altamira.\n",
    "\n",
    "#info[\"output\"] = \"/gpfs/users/martinezg/OutputCobaya/3NodesResults\"\n",
    "info[\"output\"] = \"/Users/guillermo/Desktop/4NodosBuenaPrecision/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Execute Cobaya. \n",
    "#Here, it will run in a Notebook. \n",
    "\n",
    "#from cobaya import run\n",
    "#updated_info, sampler = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
