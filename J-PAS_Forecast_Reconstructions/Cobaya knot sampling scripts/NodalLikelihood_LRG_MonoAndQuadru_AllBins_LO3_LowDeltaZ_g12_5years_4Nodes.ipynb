{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb31d82c-eee7-429d-ad38-914c33419924",
   "metadata": {},
   "source": [
    "# Script of knot sampling with Cobaya that reconstructs P_R(k) from J-PAS LRG mono/quadrupole galaxy PS data combining all z-bins #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af14be1-f148-4e89-878e-64ed04951999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sections with * indicate that they should be modify if catalogue specifications are changed\n",
    "\n",
    "#Sections with ** indicate that the path or output filenames must be modified according to the desired specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce82e1-948c-4838-a5b9-bfe865be2c37",
   "metadata": {},
   "source": [
    "# Needed packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57637a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages needed\n",
    "import cobaya\n",
    "import sys\n",
    "#Specify in this path where your CAMB is installed**\n",
    "sys.path.append('/Users/guillermo/Desktop/code/CAMB')\n",
    "import camb\n",
    "import numpy as np\n",
    "import sympy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f888a1-6da7-4fd0-9e32-bd1fd585aff2",
   "metadata": {},
   "source": [
    "# Fiducial cosmology: parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c8dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosmological constants:\n",
    "c = 2.99792458E5;   H = 1/(c/100);\n",
    "\n",
    "#Parameteres that won't be sampled:\n",
    "OmegakJPAS = 0;    gamma = 0.545;     kPivot = 0.05 #Mpc{-1}\n",
    "\n",
    "#Baseline fixed cosmology fromPlanck 2018-values TT+TE+EE+lowE+lensing. Neutrinos are assumed as 0 mass:\n",
    "AsJPAS = 2.09052E-9; nsJPAS = 0.9646; tauJPAS = 0.0544; mnuJPAS = 0.0; nmuJPAS = 3.046;\n",
    "\n",
    "#Fiducial for the baseline cosmological parameters that are going to be sampled:\n",
    "hJPAS = 0.6737\n",
    "OmegabJPASh2 = 0.02237\n",
    "OmegaCDMJPASh2 = 0.1200\n",
    "\n",
    "#Indirect cosmological parameters:\n",
    "H0JPAS = hJPAS*100\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2;   OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe824e3-5f2f-4738-ab56-fa2cba41e15e",
   "metadata": {},
   "source": [
    "# More cosmological parameters* #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bee1a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiducial cosmology functions and constants (including FoG parameter sigmap)\n",
    "\n",
    "#Omega matter:\n",
    "OmegamFid = 0.3136789606771906\n",
    "\n",
    "#Cosmological functions at all redshift bins, from the J-PAS LRG bins (i.e. z=0.1,0.3,0.5,0.7,0.9)\n",
    "EzFid = np.array([1.05063206, 1.17280592, 1.32097976, 1.49245629, 1.68459046])\n",
    "XiFid = np.array([292.61681198, 833.57665297, 1315.76329791, 1743.02284215, 2121.25261255])\n",
    "DAFid = np.array([266.01528362, 641.21280998, 877.17553194, 1025.3075542, 1116.44874345])\n",
    "sigmapFid = np.array([5.60682192, 5.04305103, 4.54769682, 4.11993136, 3.75297894])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0fddd7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Bias for the J-PAS LRG. Just divide the bias_0 (1.70) by the growth factor D(z):\n",
    "bJPAS = np.array([1.70/0.94847114, 1.70/0.85308379, 1.70/0.76926768, 1.70/0.69688361, 1.70/0.63478618 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6762a0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Area of the sky, obtained from the number of filters in the tray and the years of observation.\n",
    "\n",
    "#Choose the tray filter strategy*:\n",
    "AreaPerYear2TrayFilters = 900 #In sq degrees per year\n",
    "#AreaPerYear4TrayFilters = 450 #In sq degrees per year\n",
    "\n",
    "#Choose the observation time*:\n",
    "ObservationTime = 5 #in years\n",
    "#ObservationTime = 2.5 #in years\n",
    "\n",
    "#Calculate the area (in sq. degrees) and fraction of the sky:\n",
    "Asky = AreaPerYear2TrayFilters*ObservationTime\n",
    "fsky = Asky/(4*np.pi*(180/np.pi)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "816f6822",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Power law primordial power spectrum. Scale k must be in h units.\n",
    "def PrimordialPowerLaw(As,ns,k):\n",
    "    return As*(k/(0.05/hJPAS))**(ns-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad5b3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power law primordial power spectrum without h units.\n",
    "def PrimordialPowerLawSinh(As,ns,k):\n",
    "    return As*(k/(0.05))**(ns-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a89c3b-1536-424f-9539-01cc3c2ae464",
   "metadata": {},
   "source": [
    "# k and z binning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2750992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale and redshift bins arrays limits and steps. \n",
    "\n",
    "#Extended arrays are also calculated.\n",
    "\n",
    "#k array limits, in h Mpc{-1} units: \n",
    "khminKhArrayJPASComplete = 0.001;   khmaxKhArrayJPASComplete = 2.4900;  stepKhArrayJPASComplete = 0.025;\n",
    "\n",
    "#k binning, complete and in a reduced scaleset. In h Mpc{-1}:\n",
    "KhArrayJPASComplete = np.exp(np.arange(math.log(khminKhArrayJPASComplete), math.log(khmaxKhArrayJPASComplete), stepKhArrayJPASComplete) )\n",
    "KhArrayJPAS = KhArrayJPASComplete[range(120,212)]\n",
    "\n",
    "#k binning on lower and upper limits\n",
    "KhArrayJPASUpper = np.zeros(len(KhArrayJPAS)); KhArrayJPASLower = np.zeros(len(KhArrayJPAS));\n",
    "\n",
    "for i in range(0, len(KhArrayJPAS)-1):\n",
    "    KhArrayJPASUpper[i] = KhArrayJPAS[i] + (KhArrayJPAS[i+1]-KhArrayJPAS[i])/2;\n",
    "    KhArrayJPASLower[i] = KhArrayJPAS[i] - (KhArrayJPAS[i+1]-KhArrayJPAS[i])/2;\n",
    "\n",
    "#The last element of KUpper or KLower can be problematic. We copy the last element into the penultimate position\n",
    "KhArrayJPASUpper[-1] = KhArrayJPASUpper[-2];  KhArrayJPASLower[-1] = KhArrayJPASLower[-2];\n",
    "\n",
    "#z binning for high-z\n",
    "zJPASmin = 0.1;   zJPASmax = 0.9;   stepzJPAS = 0.2;\n",
    "\n",
    "#Original z-bin array\n",
    "zJPASPrevious = np.arange(zJPASmin, zJPASmax+stepzJPAS/2, stepzJPAS)\n",
    "\n",
    "#Element z that can be included to the array (for computing quantities at z=0)\n",
    "zJPASAdditional = np.array([0])\n",
    "\n",
    "#Binning including all lower and upper z-bins limits\n",
    "zJPAS = np.arange(zJPASmin-stepzJPAS/2, zJPASmax+0.01+stepzJPAS/2, stepzJPAS/2)\n",
    "\n",
    "#Positions of upper and lower limits of the z-bins in the z array\n",
    "positions_Upper = [2, 4, 6, 8, 10]\n",
    "positions_Lower = [0, 2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0512619-8f1a-43f1-b022-e711bddda3fd",
   "metadata": {},
   "source": [
    " # P(k) data and densities reading** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d72157cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to read the simulated data (Pk data, densities) and if neccesary for doing checks,\n",
    "# the transfer function and the seed. The path must be specified as input, and the end of this cell.\n",
    "\n",
    "\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    #Read the proper data with the proper specifications :\n",
    "    Simulated_pk_filename_z01 = path_to_data+'/LRG P_g0 forecasted data/JPAS_ForecastData_LRG_z0.1_LO3_LowDeltaZ_g12_5years.dat'\n",
    "    Simulated_pk_filename_z03 = path_to_data+'/LRG P_g0 forecasted data/JPAS_ForecastData_LRG_z0.3_LO3_LowDeltaZ_g12_5years.dat'\n",
    "    Simulated_pk_filename_z05 = path_to_data+'/LRG P_g0 forecasted data/JPAS_ForecastData_LRG_z0.5_LO3_LowDeltaZ_g12_5years.dat'\n",
    "    Simulated_pk_filename_z07 = path_to_data+'/LRG P_g0 forecasted data/JPAS_ForecastData_LRG_z0.7_LO3_LowDeltaZ_g12_5years.dat'\n",
    "    Simulated_pk_filename_z09 = path_to_data+'/LRG P_g0 forecasted data/JPAS_ForecastData_LRG_z0.9_LO3_LowDeltaZ_g12_5years.dat'\n",
    "    Simulated_densities = path_to_data+'/Densities Mini J-PAS Antonio Maroto/nlrg_12_lowdeltaz_per_bin_no_header.tex'\n",
    "\n",
    "    data['pk0z'] = np.zeros((len(zJPASPrevious), len(KhArrayJPAS))) #To allocate the monopole\n",
    "    data['pk2z'] = np.zeros((len(zJPASPrevious), len(KhArrayJPAS))) #To allocate the quadrupole\n",
    "    data['ndz'] = np.zeros(len(zJPASPrevious)) #Allocate densities\n",
    "    data['deltaz'] = np.zeros(len(zJPASPrevious)) #Allocate photometric errors delta_z\n",
    "    data['vs'] = np.zeros(len(KhArrayJPAS)) #Allocate a seed, if needed\n",
    "  \n",
    "    with open(Simulated_pk_filename_z01) as file:\n",
    "        for i in range(len(KhArrayJPAS)):\n",
    "            line = file.readline().split()\n",
    "            data['pk0z'][0][i] = float(line[7])    #In the data files, the realized monopole/quadrupole is in line 7/10\n",
    "            data['pk2z'][0][i] = float(line[10])\n",
    "            data['vs'][i] = float(line[6])\n",
    "\n",
    "    with open(Simulated_pk_filename_z03) as file:\n",
    "        for i in range(len(KhArrayJPAS)):\n",
    "            line = file.readline().split()\n",
    "            data['pk0z'][1][i] = float(line[7])\n",
    "            data['pk2z'][1][i] = float(line[10])\n",
    "\n",
    "    with open(Simulated_pk_filename_z05) as file:\n",
    "        for i in range(len(KhArrayJPAS)):\n",
    "            line = file.readline().split()\n",
    "            data['pk0z'][2][i] = float(line[7])\n",
    "            data['pk2z'][2][i] = float(line[10])\n",
    "\n",
    "    with open(Simulated_pk_filename_z07) as file:\n",
    "        for i in range(len(KhArrayJPAS)):\n",
    "            line = file.readline().split()\n",
    "            data['pk0z'][3][i] = float(line[7])\n",
    "            data['pk2z'][3][i] = float(line[10])\n",
    "            \n",
    "    with open(Simulated_pk_filename_z09) as file:\n",
    "        for i in range(len(KhArrayJPAS)):\n",
    "            line = file.readline().split()\n",
    "            data['pk0z'][4][i] = float(line[7])\n",
    "            data['pk2z'][4][i] = float(line[10])\n",
    "\n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(zJPASPrevious)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])  #Densities in line 1\n",
    "            data['deltaz'][i] = float(line[2]) #Photometric errors in line 2\n",
    "\n",
    "                          \n",
    "    return data\n",
    "\n",
    "# Read data is converted in the dictionary 'data'\n",
    "\n",
    "#Specify the path of the datafile folder:\n",
    "#data = read_data('/gpfs/users/martinezg/J-PAS_Forecast_Data/')\n",
    "data = read_data('/Users/guillermo/Desktop/J-PAS_Forecast_Data/')\n",
    "data.keys()\n",
    "\n",
    "#Create an array that includes the photometric error in the extended z-bin elements: \n",
    "DeltazLRGJPAS = np.zeros(len(zJPAS))\n",
    "\n",
    "for i in range(len(zJPASPrevious)):\n",
    "    DeltazLRGJPAS[2*i + 1] = data['deltaz'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b520f5-a566-481b-a41c-67d446760925",
   "metadata": {},
   "source": [
    "# Classes to interface with Cobaya* ** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c5d5bbc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#The classes to interface with Cobaya are created.\n",
    "\n",
    "#A cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes are created\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b36d2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class of the theory, with the PPS modification including the knots. \n",
    "#This is an example of a 4 knot case.\n",
    "\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Initialize self with the k-array.\n",
    "        self.ks = KhArrayJPAS\n",
    "\n",
    "    #Definition of knot parameters to be sampled.\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict):\n",
    "\n",
    "        #This part of the code orders the variables x in order to avoid the label switching problem.    \n",
    "        number_nodes = 4\n",
    "        number_nodes_red = number_nodes-2\n",
    "\n",
    "        megacube = np.zeros(number_nodes)\n",
    "        \n",
    "        megacube[0] = params_values_dict['x1']\n",
    "\n",
    "        megacube[1] = megacube[0] + (1 - megacube[0]) * (1 - (1 - params_values_dict['x2']) ** (1 /(number_nodes_red+1-(2-1)) ))\n",
    "        megacube[2] = megacube[1] + (1 - megacube[1]) * (1 - (1 - params_values_dict['x3']) ** (1 /(number_nodes_red+1-(3-1)) ))\n",
    "    \n",
    "        megacube[3] = params_values_dict['x4']\n",
    "\n",
    "        #Here we define que k (named 'x') and PPS nodes (named 'y').\n",
    "\n",
    "        nodes_logk = [(np.log(KhArrayJPAS[-1])-np.log(KhArrayJPAS[0]) ) * megacube[0] + np.log(KhArrayJPAS[0]), \n",
    "                      (np.log(KhArrayJPAS[-1])-np.log(KhArrayJPAS[0]) ) * megacube[1] + np.log(KhArrayJPAS[0]),\n",
    "                      (np.log(KhArrayJPAS[-1])-np.log(KhArrayJPAS[0]) ) * megacube[2] + np.log(KhArrayJPAS[0]),\n",
    "                      (np.log(KhArrayJPAS[-1])-np.log(KhArrayJPAS[0]) ) * megacube[3] + np.log(KhArrayJPAS[0])] \n",
    "        \n",
    "        nodes_logPPS = [params_values_dict['y1'], params_values_dict['y2'],params_values_dict['y3'],params_values_dict['y4']]\n",
    "\n",
    "\n",
    "\n",
    "        #nodes_k and nodes_PPS are linearly interpolated in log space. For outer values, we extraplote.\n",
    "        NodesInterpFunc_nodes = interp1d(nodes_logk, nodes_logPPS,\n",
    "        kind='linear', fill_value='extrapolate')\n",
    "\n",
    "        \n",
    "        #We construct a modified PPS(k) evaluated at our nodes and interpolated, evaluated at our k-array.\n",
    "        #The units must be without h in the limits of k\n",
    "        state['primordial_scalar_pk'] = {'kmin': KhArrayJPAS[0]*hJPAS, 'kmax': KhArrayJPAS[-1]*hJPAS,\n",
    "                                            'Pk': np.exp(NodesInterpFunc_nodes(np.log(KhArrayJPAS))), 'log_regular': True}\n",
    "        \n",
    "        \n",
    "    #Name the modified primordial power spectrum as 'primordial_scalar_pk' to be called in Cobaya.\n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "        \n",
    "    #Function that contains the parameters to be sampled.\n",
    "    def get_can_support_params(self):\n",
    "        return ['x1', 'x2', 'x3', 'x4', 'y1', 'y2','y3', 'y4']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a445de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class incorporating the model (quadrupole galaxy power spectrum) and the likelihood. \n",
    "\n",
    "class Pklike(Likelihood): \n",
    "\n",
    "    def initialize(self):  \n",
    "\n",
    "        #Path in which the data is. We call read_data with this path**.\n",
    "        #self.data = read_data('/gpfs/users/martinezg/J-PAS_Forecast_Data/')\n",
    "        self.data = read_data('/Users/guillermo/Desktop/J-PAS_Forecast_Data/')\n",
    "\n",
    "        #k-array\n",
    "        self.ks = KhArrayJPAS\n",
    "        \n",
    "        #z-bins\n",
    "        self.z_win = zJPAS\n",
    "\n",
    "    \n",
    "    def get_requirements(self): #Cobaya functions that we might use.\n",
    "        \n",
    "        return {'omegam': None,                \n",
    "                'Pk_interpolator': {'z': self.z_win, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_win},\n",
    "                'angular_diameter_distance': {'z': self.z_win},\n",
    "                'Hubble': {'z': self.z_win, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_win}, 'fsigma8': {'z': self.z_win},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    "\n",
    "        \n",
    "    #Definition of the multipoles: monopole and quadrupole. It will return:\n",
    "        #The monopole evaluated at the z-bins and the k-array.\n",
    "        #The monopole covariance evaluated at the z-bins and the k-array.  \n",
    "    \n",
    "        #The quadrupole evaluated at the z-bins and the k-array.\n",
    "        #The quadrupole covariance evaluated at the z-bins and the k-array.  \n",
    "    \n",
    "    def multipoles(self, **params_dic):\n",
    "        \n",
    "        #Options for print with enough decimal precision, if needed\n",
    "        #np.set_printoptions(precision=24, suppress=True)\n",
    "\n",
    "        #CAMB results within Cobaya\n",
    "        resultsCobaya = self.provider.get_CAMBdata() \n",
    "\n",
    "        #This is the modified primordial power spectrum P(k) evaluated at KArray.\n",
    "        primordialCobaya = self.provider.get_primordial_scalar_pk()\n",
    "        \n",
    "        #Construction of Pmatter(k) calling Cobaya:\n",
    "        pkCobaya = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False) \n",
    "        \n",
    "        # All functions and variables to compute the Kaiser model. It reads the cosmology from info (below)\n",
    "        \n",
    "        #Cosmological parameters from CAMB\n",
    "        Omegam = self.provider.get_param('omegam')  \n",
    "\n",
    "        #Cosmological functions\n",
    "        Ez = np.sqrt( Omegam*(1+self.z_win)**3+(1-Omegam) ); \n",
    "        HJPAS = H * Ez\n",
    "        f = (Omegam*(1+self.z_win)**3*1/(Ez**2))**gamma\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_win)*hJPAS; #CAMB is called here\n",
    "\n",
    "        DA = Xi/(1+self.z_win);\n",
    "        \n",
    "        # Photometric factor\n",
    "        sigmar = DeltazLRGJPAS*(1+self.z_win)/HJPAS\n",
    "\n",
    "        # Fingers of God effect at proper z-bin in the fiducial\n",
    "        def FFog(mu,k,iz):\n",
    "            return 1/(1+(f[2*iz-1]*k*mu*sigmapFid[iz-1])**2)\n",
    "      \n",
    "        # AP effect\n",
    "        def FactorAP(iz):\n",
    "            return DAFid[iz-1]**2*Ez[2*iz-1]/( DA[2*iz-1]**2*EzFid[iz-1] )\n",
    "\n",
    "        def Q(mu,iz):\n",
    "            return ((Ez[2*iz-1]**2*Xi[2*iz-1]**2*mu**2-EzFid[iz-1]**2*XiFid[iz-1]**2*(mu**2-1))**0.5/(EzFid[iz-1]*Xi[2*iz-1]))\n",
    "\n",
    "        def muObs(mu,iz):\n",
    "            return mu*Ez[2*iz-1]/(EzFid[iz-1]*Q(mu,iz))\n",
    "\n",
    "        def kObs(mu,k,iz):\n",
    "            return Q(mu,iz)*k\n",
    "\n",
    "        #Galaxy Power spectrum (mu,k) with AP and FoG. The Pmatter of Cobaya must be evaluated at k without h units\n",
    "        def Pg(mu,k,iz):\n",
    "            return FactorAP(iz)*FFog(muObs(mu,iz),kObs(mu,k,iz),iz)*(bJPAS[iz-1]+f[2*iz-1]*muObs(mu,iz)**2)**2 * (   hJPAS**3*(   pkCobaya.P(self.z_win[2*iz-1],kObs(mu,k,iz)*hJPAS)   )   ) *np.exp(-(k*mu*sigmar[2*iz-1])**2)\n",
    "        \n",
    "\n",
    "\n",
    "        #Monopole and quadrupole galaxy power spectra\n",
    "\n",
    "        #Trapezoid rule with 2000 steps for computing the multipoles:\n",
    "\n",
    "        def Pgmonopole(k,iz):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 1/2 * integrate.trapz(Pg(mu, k, iz), mu)\n",
    "                    \n",
    "        def Pgquadrupole(k,iz):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 5/2 * integrate.trapz(Pg(mu, k, iz) * 0.5 * (3*mu**2-1), mu)\n",
    "\n",
    "       \n",
    "        #We evaluate both monopole and quadrupole power spectra in our k-array and z-bins\n",
    "        PgmonopoleValues = np.zeros((len(zJPASPrevious), len(KhArrayJPAS)))\n",
    "        PgquadrupoleValues = np.zeros((len(zJPASPrevious), len(KhArrayJPAS)))\n",
    "\n",
    "\n",
    "        for j in range(len(zJPASPrevious)):\n",
    "            for i in range(len(KhArrayJPAS)):\n",
    "                PgmonopoleValues[j, i] = Pgmonopole(KhArrayJPAS[i], j+1)\n",
    "                PgquadrupoleValues[j, i] = Pgquadrupole(KhArrayJPAS[i], j+1)\n",
    "\n",
    "                 \n",
    "        #Covariance matrixes\n",
    "\n",
    "        #Angular distance for z upper and lower bins from CAMB\n",
    "        XiZaLower = self.provider.get_comoving_radial_distance(self.z_win[positions_Lower])*hJPAS\n",
    "        XiZaUpper = self.provider.get_comoving_radial_distance(self.z_win[positions_Upper])*hJPAS\n",
    "        \n",
    "        #Definition of the volume between redshift bins\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "        \n",
    "        \n",
    "        #Number of modes. It depends of ksup and kinf corresponding to kupper y klower\n",
    "        def Nk(ksup,kinf,iz):\n",
    "            return Vol[iz-1] * (4*np.pi/3*(ksup**3-kinf**3))/((2*np.pi)**3)\n",
    "\n",
    "        \n",
    "        #Number of nodes evaluated at our arrays.\n",
    "        NkEvaluated = np.zeros((len(zJPASPrevious), len(KhArrayJPASUpper)))\n",
    "\n",
    "        for j in range(len(zJPASPrevious)):\n",
    "            for i in range(len(KhArrayJPASUpper)):     \n",
    "                NkEvaluated[j, i] = Nk(KhArrayJPASUpper[i], KhArrayJPASLower[i], j+1)\n",
    "\n",
    "\n",
    "\n",
    "        #We compute the value of the monopole Covariance Matrix evaluated at the k-arrays for all the bins:\n",
    "\n",
    "        CovMonopoleEvaluatedz01 = 2 *(PgmonopoleValues[0] + 1/self.data['ndz'][0])**2 / NkEvaluated[0]\n",
    "        CovMonopoleEvaluatedz03 = 2 *(PgmonopoleValues[1] + 1/self.data['ndz'][1])**2 / NkEvaluated[1]\n",
    "        CovMonopoleEvaluatedz05 = 2 *(PgmonopoleValues[2] + 1/self.data['ndz'][2])**2 / NkEvaluated[2]\n",
    "        CovMonopoleEvaluatedz07 = 2 *(PgmonopoleValues[3] + 1/self.data['ndz'][3])**2 / NkEvaluated[3]\n",
    "        CovMonopoleEvaluatedz09 = 2 *(PgmonopoleValues[4] + 1/self.data['ndz'][4])**2 / NkEvaluated[4]\n",
    "\n",
    "        \n",
    "        CovQuadrupoleEvaluatedz01 = 2 *(PgquadrupoleValues[0] + 1/self.data['ndz'][0])**2 / NkEvaluated[0]\n",
    "        CovQuadrupoleEvaluatedz03 = 2 *(PgquadrupoleValues[1] + 1/self.data['ndz'][1])**2 / NkEvaluated[1]\n",
    "        CovQuadrupoleEvaluatedz05 = 2 *(PgquadrupoleValues[2] + 1/self.data['ndz'][2])**2 / NkEvaluated[2]\n",
    "        CovQuadrupoleEvaluatedz07 = 2 *(PgquadrupoleValues[3] + 1/self.data['ndz'][3])**2 / NkEvaluated[3]\n",
    "        CovQuadrupoleEvaluatedz09 = 2 *(PgquadrupoleValues[4] + 1/self.data['ndz'][4])**2 / NkEvaluated[4]\n",
    "\n",
    "        #The function multipoles returns the monopole values for each z-bin, its covariance, and the same with the quadrupole.\n",
    "        return PgmonopoleValues[0], PgmonopoleValues[1], PgmonopoleValues[2], PgmonopoleValues[3], PgmonopoleValues[4], CovMonopoleEvaluatedz01, CovMonopoleEvaluatedz03, CovMonopoleEvaluatedz05, CovMonopoleEvaluatedz07, CovMonopoleEvaluatedz09, PgquadrupoleValues[0], PgquadrupoleValues[1], PgquadrupoleValues[2], PgquadrupoleValues[3], PgquadrupoleValues[4], CovQuadrupoleEvaluatedz01, CovQuadrupoleEvaluatedz03, CovQuadrupoleEvaluatedz05, CovQuadrupoleEvaluatedz07, CovQuadrupoleEvaluatedz09\n",
    "\n",
    "\n",
    "    #Likelihood calculation. We define the likelihood.\n",
    "    \n",
    "    def logp(self, **params_values):  \n",
    "        \n",
    "        \n",
    "        #For allocating the multipoles values and their cov values.\n",
    "\n",
    "        #For the monopole:\n",
    "        PmonopoleBined = np.zeros((len(zJPASPrevious), len(self.ks)))\n",
    "        CovMonopoleBined = np.zeros((len(zJPASPrevious), len(self.ks)))\n",
    "\n",
    "        #For the quadrupole:\n",
    "        PquadrupoleBined = np.zeros((len(zJPASPrevious), len(self.ks)))\n",
    "        CovQuadrupoleBined = np.zeros((len(zJPASPrevious), len(self.ks)))\n",
    "\n",
    "        #PmonopoleBined, CovMonopoleBined, PquadrupoleBined and CovQuadrupoleBined are equal\n",
    "        #to the values given by the self.multipoles function:\n",
    "        PmonopoleBined[0, :len(self.ks)], PmonopoleBined[1, :len(self.ks)], PmonopoleBined[2, :len(self.ks)], PmonopoleBined[3, :len(self.ks)], PmonopoleBined[4, :len(self.ks)], CovMonopoleBined[0, :len(self.ks)], CovMonopoleBined[1, :len(self.ks)], CovMonopoleBined[2, :len(self.ks)], CovMonopoleBined[3, :len(self.ks)], CovMonopoleBined[4, :len(self.ks)], PquadrupoleBined[0, :len(self.ks)], PquadrupoleBined[1, :len(self.ks)], PquadrupoleBined[2, :len(self.ks)], PquadrupoleBined[3, :len(self.ks)], PquadrupoleBined[4, :len(self.ks)], CovQuadrupoleBined[0, :len(self.ks)], CovQuadrupoleBined[1, :len(self.ks)], CovQuadrupoleBined[2, :len(self.ks)], CovQuadrupoleBined[3, :len(self.ks)], CovQuadrupoleBined[4, :len(self.ks)] = self.multipoles(**params_values)\n",
    "        \n",
    "\n",
    "        #Construction of the likelihood like a chi^2 with the log of determinant term\n",
    "        lnlike = 0.0\n",
    "\n",
    "        #Here the inclusion of the quadrupole and different z-bins can be done:\n",
    "        for i in range(len(KhArrayJPAS)):\n",
    "            #For all bins (0-4) and for both monopole and quadrupole.\n",
    "            lnlike = lnlike + ((PmonopoleBined[0][i] - data['pk0z'][0][i])**2 *1/CovMonopoleBined[0][i] + np.log(CovMonopoleBined[0][i])) +  ((PmonopoleBined[1][i] - data['pk0z'][1][i])**2 *1/CovMonopoleBined[1][i] + np.log(CovMonopoleBined[1][i])) + ((PmonopoleBined[2][i] - data['pk0z'][2][i])**2 *1/CovMonopoleBined[2][i] + np.log(CovMonopoleBined[2][i])) + ((PmonopoleBined[3][i] - data['pk0z'][3][i])**2 *1/CovMonopoleBined[3][i] + np.log(CovMonopoleBined[3][i])) + ((PmonopoleBined[4][i] - data['pk0z'][4][i])**2 *1/CovMonopoleBined[4][i] + np.log(CovMonopoleBined[4][i])) + ((PquadrupoleBined[0][i] - data['pk2z'][0][i])**2 *1/CovQuadrupoleBined[0][i] + np.log(CovQuadrupoleBined[0][i])) +  ((PquadrupoleBined[1][i] - data['pk2z'][1][i])**2 *1/CovQuadrupoleBined[1][i] + np.log(CovQuadrupoleBined[1][i])) + ((PquadrupoleBined[2][i] - data['pk2z'][2][i])**2 *1/CovQuadrupoleBined[2][i] + np.log(CovQuadrupoleBined[2][i])) + ((PquadrupoleBined[3][i] - data['pk2z'][3][i])**2 *1/CovQuadrupoleBined[3][i] + np.log(CovQuadrupoleBined[3][i])) + ((PquadrupoleBined[4][i] - data['pk2z'][4][i])**2 *1/CovQuadrupoleBined[4][i] + np.log(CovQuadrupoleBined[4][i]))\n",
    "            \n",
    "            #For all bins (0-4) and for only the monopole.\n",
    "            #lnlike = lnlike + ((PmonopoleBined[0][i] - data['pk0z'][0][i])**2 *1/CovMonopoleBined[0][i] + np.log(CovMonopoleBined[0][i])) +  ((PmonopoleBined[1][i] - data['pk0z'][1][i])**2 *1/CovMonopoleBined[1][i] + np.log(CovMonopoleBined[1][i])) + ((PmonopoleBined[2][i] - data['pk0z'][2][i])**2 *1/CovMonopoleBined[2][i] + np.log(CovMonopoleBined[2][i])) + ((PmonopoleBined[3][i] - data['pk0z'][3][i])**2 *1/CovMonopoleBined[3][i] + np.log(CovMonopoleBined[3][i])) + ((PmonopoleBined[4][i] - data['pk0z'][4][i])**2 *1/CovMonopoleBined[4][i] + np.log(CovMonopoleBined[4][i]))\n",
    "        \n",
    "            #For the first and fifth bins (0 and 4) of the monopole.\n",
    "            #lnlike = lnlike + ((PmonopoleBined[0][i] - data['pk0z'][0][i])**2 *1/CovMonopoleBined[0][i] + np.log(CovMonopoleBined[0][i])) +  + ((PmonopoleBined[4][i] - data['pk0z'][4][i])**2 *1/CovMonopoleBined[4][i] + np.log(CovMonopoleBined[4][i]))\n",
    "\n",
    "        return -lnlike/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26025592-2e74-4bae-9a51-c40627c9c596",
   "metadata": {},
   "source": [
    "# Planck priors (correlated) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b5d3046",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Creation of the multivariate gaussian that will be used as prior\n",
    "\n",
    "#Mean values of the Multivariate gaussian for each dimension\n",
    "mean_vector = [OmegabJPASh2, OmegaCDMJPASh2, H0JPAS]\n",
    "\n",
    "# Covariance matrix for Planck TTTEEE low l low E lensing.\n",
    "# Order: Omegabh2, Omegach2 and H0\n",
    "PlanckDR3_base_plikHM_TTTEEE_lowl_lowE_lensing_covMatrix = np.array([\n",
    "    [2.12418149e-08, -9.03204492e-08, 5.50402459e-05],\n",
    "    [-9.03204492e-08, 1.38810729e-06, -6.02340614e-04],\n",
    "    [5.50402459e-05, -6.02340614e-04, 2.86660525e-01]\n",
    "])\n",
    "\n",
    "#Components of the manual 3D guassian to be created:\n",
    "\n",
    "#Determinant:\n",
    "determinant = np.linalg.det(PlanckDR3_base_plikHM_TTTEEE_lowl_lowE_lensing_covMatrix)\n",
    "\n",
    "#Inverse matrix:\n",
    "if determinant != 0:\n",
    "    inverse_matrix = np.linalg.inv(PlanckDR3_base_plikHM_TTTEEE_lowl_lowE_lensing_covMatrix)\n",
    "else:\n",
    "    print(\"The matrix is singular and does not have an inverse.\")\n",
    "\n",
    "#Residuals Vector:\n",
    "def ResidualsVector(ombh2, omch2, H0):\n",
    "    return np.array([ombh2-OmegabJPASh2,omch2-OmegaCDMJPASh2,H0-H0JPAS])\n",
    "\n",
    "#Construction of the normalized pdf (we include the log the the logpriors and the -1/2 factor):\n",
    "def multivariate_gaussian_pdf(ombh2, omch2, H0):\n",
    "    return np.log((2*np.pi)**(-3/2)*determinant**(-1/2)*np.exp(-1/2* np.dot(np.transpose(ResidualsVector(ombh2, omch2, H0)),np.dot(inverse_matrix,ResidualsVector(ombh2, omch2, H0)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f6c63-e5c4-427a-869e-3eec8d3b644f",
   "metadata": {},
   "source": [
    "# Cobaya Info** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3485f5f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Dictionary given to Cobaya. We need to specify:\n",
    "    #Likelihood (class including the likelihood and the model).\n",
    "    #Theory class (in which we modify the PPS to have knots).\n",
    "    #Parameters (fixed and to be sampled).\n",
    "    #Sampler to be used and specifications.\n",
    "    #Output where save the output.\n",
    "    #Afitional options as debugind or resuming chains.\n",
    "\n",
    "\n",
    "info = {'debug': False,                        #Allow to debug\n",
    "        'likelihood': {'jpass': Pklike},       #Link likelihood with the previously defined clss\n",
    "        'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "                   'my_pk': NodesInPrimordialPk},      #We include the primordial Pk with nodes in the theory class\n",
    "       'params': {\n",
    "           \n",
    "        # Fixed cosmological parameters. We include the extremal knots in this category.\n",
    "        'tau': tauJPAS, 'mnu': mnuJPAS, 'nnu': nmuJPAS,\n",
    "        'x1': 0.0,\n",
    "        'x4': 1.0,\n",
    "           \n",
    "        #Also it seems to be neccesary to include the cosmological parameters, although later they will be sampled.\n",
    "        'ombh2': OmegabJPASh2, 'omch2': OmegaCDMJPASh2, 'H0': H0JPAS,\n",
    "           \n",
    "        #Parameters to be sampled. Knot parameters with flat priors:\n",
    "        'y1': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_1'},\n",
    "        'y2': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_2'},\n",
    "        'y3': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_3'},\n",
    "        'y4': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'latex': 'y_4'},\n",
    "        'x2': {'prior': {'min': 0.0, 'max': 1.0}, 'ref': 0.5, 'latex': 'x_2'},\n",
    "        'x3': {'prior': {'min': 0.0, 'max': 1.0}, 'ref': 0.5, 'latex': 'x_3'}, \n",
    "        \n",
    "        # Cosmological parameters to be sampled. Loc and scale are the mean value and the st deviation for a guassian prior:\n",
    "        'ombh2': {'prior': {'dist': 'norm', 'loc': OmegabJPASh2, 'scale': 0.00015}, 'latex': 'Omega_bh^2'},\n",
    "        'omch2': {'prior': {'dist': 'norm', 'loc': OmegaCDMJPASh2, 'scale': 0.0012}, 'latex': 'Omega_ch^2'},\n",
    "        'H0': {'prior': {'dist': 'norm', 'loc': H0JPAS, 'scale': 0.54}, 'latex': 'H_0'}},\n",
    "\n",
    "        #Here the setting of the sampler are chosen. We employ PolyChord. \n",
    "        #The nlive by default  equal to 25 * params to be sampled (i.g. 225).\n",
    "        \"sampler\": {\"polychord\":\n",
    "                        {\"precision_criterion\": 5e-3}\n",
    "                    }\n",
    "           }\n",
    "\n",
    "#Prior imposed to the sampled cosmological parameters. We employ correlated posteriors according to Planck 2018 TTTEEE low l low E lensing\n",
    "#as defined above:\n",
    "info[\"prior\"] = {\"Multivariate\": lambda ombh2, omch2, H0: multivariate_gaussian_pdf(ombh2, omch2, H0)} \n",
    "\n",
    "#Path for output folder and name of the directory**\n",
    "\n",
    "#info[\"output\"] = \"/gpfs/users/martinezg/OutputCobaya_JPAS_LRG/AllBins/LO1_LowDeltaZ_g12_5years_4Nodes_Results\"\n",
    "info[\"output\"] = \"/Users/guillermo/Desktop/ProofGitHub/OutputCobaya_JPAS_LRG/AllBins/LO1_MonoAndQuadru_LowDeltaZ_g12_5years_4Nodes_Results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b42c44-f72a-48a3-9e52-c0dcc152ca93",
   "metadata": {},
   "source": [
    "# Run Cobaya #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b8f8d4-baf6-469f-90ff-dbe835fbb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute Cobaya:\n",
    "\n",
    "from cobaya import run\n",
    "updated_info, sampler = run(info)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
