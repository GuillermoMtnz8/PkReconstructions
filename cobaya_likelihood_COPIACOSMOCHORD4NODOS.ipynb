{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to be loaded. Probably there are duplicated or missing ones\n",
    "import cobaya\n",
    "import camb\n",
    "import numpy as np\n",
    "import sympy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmological parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosmological constants\n",
    "c = 2.99792458E5;   HJPAS = 1/(c/100);\n",
    "\n",
    "#Parameteres that won't be sampled. These parameters will be the same as the ones given to Cobaya\n",
    "gamma = 0.545; OmegakJPAS = 0; AsJPAS = 2.09052E-9; nsJPAS = 0.9626; tauJPAS = 0.06; mnuJPAS = 0.0; nmuJPAS = 3.046;\n",
    "\n",
    "#A set of cosmological parameters outside the fiducial cosmology matching Cobaya's cosmology\n",
    "hJPAS = 0.674\n",
    "OmegabJPASh2 = 0.02212\n",
    "OmegaCDMJPASh2 = 0.1206\n",
    "\n",
    "#Indirect cosmological parameters outside the fiducial\n",
    "H0JPAS = hJPAS*100\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2; OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiducial cosmology functions and constants (including FoG parameter)\n",
    "OmegamFid = 0.31417\n",
    "\n",
    "#At z=1.7 (first bin)\n",
    "EzFid = 2.6210003044889154\n",
    "XiFid = 3263.0797256936944\n",
    "DAFid = 1208.54804655322\n",
    "sigmapFid = 2.725068353464309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros de LSS de JPAS\n",
    "DeltazJPAS = 0.00364236313918151\n",
    "fsky = 0.2575\n",
    "\n",
    "def bJPAS(z):\n",
    "    return 0.53+0.289*(1+z)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimordialPowerLaw(As,ns,k):\n",
    "    return As*(k/(0.05/hJPAS))**(ns-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k and z binning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays limits and steps.\n",
    "\n",
    "#K arrays. In h units\n",
    "\n",
    "kminKArrayCompleto = 0.001;   kmaxKArrayCompleto = 2.4900;  pasoKArrayCompleto = 0.025;\n",
    "zmin = 1.7;   zmax = 2.9;   pasoz = 0.2;\n",
    "\n",
    "#k binning, complete and in a reduced scaleset\n",
    "KArrayCompleto = np.exp(np.arange(math.log(kminKArrayCompleto), math.log(kmaxKArrayCompleto), pasoKArrayCompleto) )\n",
    "KArray = KArrayCompleto[range(121,246)]\n",
    "\n",
    "#k binning on lower and upper limits\n",
    "KArrayUpper = np.zeros(len(KArray)); KArrayLower = np.zeros(len(KArray));\n",
    "\n",
    "for i in range(0, len(KArray)-1):\n",
    "    KArrayUpper[i] = KArray[i] + (KArray[i+1]-KArray[i])/2;   KArrayLower[i] = KArray[i] - (KArray[i+1]-KArray[i])/2;\n",
    "\n",
    "KArrayUpper[-1] = KArrayUpper[-2];  KArrayLower[-1] = KArrayLower[-2];\n",
    "\n",
    "\n",
    "#z binning\n",
    "\n",
    "#Original one\n",
    "zaAntes = np.arange(zmin-0.1, zmax+pasoz/2, pasoz)\n",
    "\n",
    "#Including z=0\n",
    "zaAdicional = np.array([0])\n",
    "\n",
    "#Binning including all lower and upper z-bins limits\n",
    "zaConBines = np.arange(zmin-pasoz/2, zmax+0.01+pasoz/2, pasoz/2)\n",
    "\n",
    "#z binning with 0 and including z-bin limits\n",
    "za = np.concatenate((zaAdicional,zaConBines))\n",
    "\n",
    "#Positions of upper and lower limits of the z-bins in the za array\n",
    "positions_Upper = [3, 5, 7, 9, 11, 13, 15]\n",
    "positions_Lower = [1, 3, 5, 7, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(k) data and densities reading #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pkz', 'ndz', 'vs', 'tk', 'Nk'])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a class to read the simulated data (Pk, densities) and the seed specifying the path as input\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    Simulated_pk_filename = path_to_data+'CosmoChordKData.dat'\n",
    "    Simulated_densities = path_to_data+'Densities_HighZ.dat'\n",
    "    Vector_Seed = path_to_data+'SeedVector.dat'\n",
    "\n",
    "    data['pkz'] = np.zeros((len(zaAntes), len(KArray)))\n",
    "    data['ndz'] = np.zeros(len(zaAntes))\n",
    "    data['vs'] = np.zeros(len(KArray))\n",
    "    data['tk'] = np.zeros(len(KArray))\n",
    "    data['Nk'] = np.zeros(len(KArray))\n",
    "  \n",
    "    with open(Simulated_pk_filename) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['pkz'][0][i] = float(line[2])\n",
    "            data['tk'][i] = float(line[1])\n",
    "            data['Nk'][i] = float(line[3])\n",
    "            \n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(zaAntes)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])\n",
    "\n",
    "    with open(Vector_Seed) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['vs'][i] = float(line[0])\n",
    "                  \n",
    "            \n",
    "    return data\n",
    "\n",
    "# Read data is converted in the dictionary 'data'\n",
    "\n",
    "#data = read_data('/gpfs/users/martinezg/Simulated_Data/')\n",
    "data = read_data('/Users/guillermo/Desktop/Simulated_Data/')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to interface with Cobaya #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If previous is OK, now the classes to interface with Cobaya are created.\n",
    "\n",
    "#A cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes are created\n",
    "\n",
    "#Needed packages\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class of the theory, with the PPS modification including the nodes\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Initialize self with the k-array\n",
    "        self.ks = KArray\n",
    "\n",
    "    #It seems that in here we allocate the values of the parameters to be sampled and definme their names\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict):\n",
    "\n",
    "        #Variables k1, k2... P1, P2... Allocated here\n",
    "        #nodes_k = [params_values_dict['k1'], params_values_dict['k2'], params_values_dict['k3']  ] \n",
    "        #nodes_PPS = [params_values_dict['P1'], params_values_dict['P2'], params_values_dict['P3']] \n",
    "\n",
    "\n",
    "\n",
    "        nodes_logk = [(np.log(KArray[-1])-np.log(KArray[0]) ) * params_values_dict['x1'] + np.log(KArray[0]), \n",
    "                      (np.log(KArray[-1])-np.log(KArray[0]) ) * params_values_dict['x2'] + np.log(KArray[0]),\n",
    "                      (np.log(KArray[-1])-np.log(KArray[0]) ) * params_values_dict['x3'] + np.log(KArray[0]),\n",
    "                      (np.log(KArray[-1])-np.log(KArray[0]) ) * params_values_dict['x4'] + np.log(KArray[0])] \n",
    "        nodes_logPPS = [params_values_dict['y1'], params_values_dict['y2'],params_values_dict['y3'],params_values_dict['y4']] \n",
    "\n",
    "        \n",
    "        #nodes_k and nodes_PPS are interpolated\n",
    "        NodesInterpFunc_nodes = interp1d(nodes_logk, nodes_logPPS,\n",
    "                axis=0,  # interpolate along columns\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_logPPS[0], nodes_logPPS[-1]))\n",
    "        \n",
    "        #We construct a modified PPS(k) is evaluated at our nodes, evaluated at our array\n",
    "        state['primordial_scalar_pk'] = {'kmin': KArray[0], 'kmax': KArray[-1],\n",
    "                                         'Pk': np.exp(NodesInterpFunc_nodes(np.log(KArray))), 'log_regular': True}\n",
    "\n",
    "    #To be able to evaluate the PPS?\n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "   \n",
    "    #Function that returns the nodes parameters values\n",
    "    def get_can_support_params(self):\n",
    "        return ['x1', 'x2','x3','x4', 'y1', 'y2','y3','y4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class incorporating the monopole and the likelihood. \n",
    "\n",
    "\n",
    "class Pklike(Likelihood): #Class is defined\n",
    "    \n",
    "    def initialize(self):  \n",
    "\n",
    "        #Path in wich the data are. We call read_data with this path.\n",
    "        #self.data = read_data('/gpfs/users/martinezg/Simulated_Data/')\n",
    "        self.data = read_data('/Users/guillermo/Desktop/Simulated_Data/')\n",
    "\n",
    "        #Grid of K\n",
    "        self.ks = KArray\n",
    "        \n",
    "        #Grid of z to be employed\n",
    "        self.z_win = za\n",
    "\n",
    "    \n",
    "    def get_requirements(self): #¿Por qué es necesario tener requisitos? ¿No puedo usar las funciones sin esto?\n",
    "                                #¿Interpolator en extended o completo?\n",
    "        \n",
    "        return {'omegam': None,                \n",
    "                'Pk_interpolator': {'z': self.z_win, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_win},\n",
    "                'angular_diameter_distance': {'z': self.z_win},\n",
    "                'Hubble': {'z': self.z_win, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_win}, 'fsigma8': {'z': self.z_win},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    " \n",
    "    #Definition of the monopole. It will return:\n",
    "        #The monopole evaluated at z=1.7 and array of k\n",
    "        #The covariance evaluated at z=1.8 and array of k\n",
    "    \n",
    "    def monopole(self, **params_dic):\n",
    "\n",
    "        np.set_printoptions(precision=24, suppress=True)\n",
    "        \n",
    "        #Definimos el matter power spectrum\n",
    "        \n",
    "        #This is the primordial power spectrum, evaluatedd at KArray with its minimum and maximum limits.\n",
    "        primordialCobaya = self.provider.get_primordial_scalar_pk()\n",
    "\n",
    "        \n",
    "        def Pmatter(k):\n",
    "            #Aquí cuando metemos la power law estática\n",
    "            #return 2*np.pi**2*hJPAS**4*k*data['tk']**2*PrimordialPowerLaw(AsJPAS,nsJPAS,k)\n",
    "\n",
    "            #Aquí metemos nuestro primordial llamando desde los nodos:\n",
    "            return 2*np.pi**2*hJPAS**4*k*data['tk']**2*primordialCobaya['Pk']\n",
    "\n",
    "        \n",
    "        resultsCobaya = self.provider.get_CAMBdata()   #CAMB results in resultsCobaya  \n",
    "\n",
    "        # All functions and variables to compute the Kaiser model. It reads the cosmology from info (below)\n",
    "        Omegam = self.provider.get_param('omegam')  \n",
    "\n",
    "        self.provider.get_param('omegam') \n",
    "\n",
    "        Ez = np.sqrt( Omegam*(1+self.z_win)**3+(1-Omegam) ); \n",
    "        H = HJPAS * Ez\n",
    "        f = (Omegam*(1+self.z_win)**3*1/(Ez**2))**gamma\n",
    "       \n",
    "\n",
    "        #A and R parameters withouth D(z) (thus calculating online Pm(1.7))\n",
    "        A = bJPAS(za)\n",
    "        R = f\n",
    "\n",
    "        # This is the matter power spectrum interpolator:\n",
    "        pkCobaya = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)    #P matter is obtained here\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Photometric factor\n",
    "        sigmar = DeltazJPAS*(1+self.z_win)/H\n",
    "\n",
    "        # Fingers of God effect at z = 1.7 in the fiducial\n",
    "\n",
    "        def FFog(mu,k):\n",
    "            return 1/(1+(f[2]*k*mu*sigmapFid)**2)\n",
    "\n",
    "\n",
    "        # AP effect\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_win)*hJPAS;\n",
    "        DA = Xi/(1+self.z_win);\n",
    "        FactorAP = DAFid**2*EzFid/( DA[2]**2*EzFid )\n",
    "\n",
    "        def Q(mu):\n",
    "            return ((Ez[2]**2*Xi[2]**2*mu**2-EzFid**2*XiFid**2*(mu**2-1))**0.5/(EzFid*Xi[2]))\n",
    " \n",
    "        def muObs(mu):\n",
    "            return mu*Ez[2]/(EzFid*Q(mu))\n",
    "           \n",
    "        def kObs(mu,k):\n",
    "            return Q(mu)*k \n",
    "\n",
    "\n",
    "        #P galaxy\n",
    "        def Pg(mu,k):\n",
    "            return FactorAP*FFog(muObs(mu),kObs(mu,k))*(A[2]+R[2]*muObs(mu)**2)**2 * (   hJPAS**3*pkCobaya.P(self.z_win[2],kObs(mu,k)*hJPAS)   ) *np.exp(-(k*mu*sigmar[2])**2)\n",
    "    \n",
    "        #Trapezoid rule with 2000 steps for computing the Pmonopole(k)\n",
    "        #def Pgmonopole(k):\n",
    "            #mu = np.arange(-1, 1, 1/1000)\n",
    "            #return 1/2 * integrate.trapz(Pg(mu, k), mu)\n",
    "\n",
    "        def Pgmonopole(k):\n",
    "            term1 = (np.sqrt(np.pi) * erf(k * sigmar[2]) * (4 * A[2]**2 * k**4 * sigmar[2]**4 + 4 * A[2] * k**2 * R[2] * sigmar[2]**2 + 3 * R[2]**2))\n",
    "            term2 = (-2 * k * R[2] * sigmar[2] * np.exp(-k**2 * sigmar[2]**2) * (2 * k**2 * sigmar[2]**2 * (2 * A[2] + R[2]) + 3 * R[2]))\n",
    "            return (   Pmatter(k)   ) * (term1 + term2) / (8 * k**5  * sigmar[2]**5)\n",
    "\n",
    "        \n",
    "        #PgmonopoleValores = [None] * len(self.ks)\n",
    "\n",
    "        \n",
    "        #for i in range(0, len(self.ks)-1):\n",
    "            #PgmonopoleValores[i] = Pgmonopole(self.ks[i])\n",
    "\n",
    "        PgmonopoleValores = Pgmonopole(KArray)\n",
    "\n",
    "        #Covariance\n",
    "        \n",
    "        #Densities are red from self.data['ndz].\n",
    "\n",
    "        #Definition of the volume (requires angular distance and za lower/upper bining)\n",
    "\n",
    "\n",
    "        #Angular distance for z upper and lower bins.\n",
    "\n",
    "        XiZaLower = self.provider.get_comoving_radial_distance(self.z_win[positions_Lower])*hJPAS\n",
    "        XiZaUpper = self.provider.get_comoving_radial_distance(self.z_win[positions_Upper])*hJPAS\n",
    "        \n",
    "        #Definition of the volume between redshift bins\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "   \n",
    "        #Number of modes. It depends of ksup and kinf corresponding to kupper y klower\n",
    "        def Nk(ksup,kinf):\n",
    "            return Vol[0] * (4*np.pi/3*(ksup**3-kinf**3))/((2*np.pi)**3)\n",
    "\n",
    "        #Nk evaluated for each of our k-bins\n",
    "        NkEvaluado = np.zeros(len(self.ks))\n",
    "        for i in range(0, len(self.ks)):\n",
    "            NkEvaluado[i] = data['Nk'][i]\n",
    "        \n",
    "        #Covariance Cov definition\n",
    "        def Cov(k,k1,k2):\n",
    "            return 2 * (Pgmonopole(k) + 1/self.data['ndz'][0])**2 / Nk(k1,k2)\n",
    "\n",
    "        \n",
    "        #Cov evaluated at our k array\n",
    "        CovEvaluado = 2 *(PgmonopoleValores + 1/self.data['ndz'][0])**2 / NkEvaluado\n",
    "\n",
    "        #print(PgmonopoleValores[0])\n",
    "        \n",
    "        #We return the value of the monopole at our k-array and of the Covariance Matrix at the same array\n",
    "\n",
    "\n",
    "\n",
    "        #Part in which we simulated the Pg data\n",
    "        #PgWithSeed = np.sqrt(CovEvaluado)*data['vs'] + PgmonopoleValores \n",
    "        #PgWithSeed = PgWithSeed = np.sqrt(CovEvaluado)*data['vs'] + PgmonopoleValores    \n",
    "        #PgData = np.column_stack((KArray, PgWithSeed, np.sqrt(CovEvaluado)))\n",
    "        #PgDataFile = 'PgDataFile2Nodes.dat'\n",
    "        #np.savetxt(PgDataFile, PgData, delimiter='\\t', comments='')\n",
    "\n",
    "        #print((   hJPAS**3*pkCobaya.P(self.z_win[2],KArray*hJPAS)   ))\n",
    "\n",
    "        \n",
    "        return PgmonopoleValores, CovEvaluado\n",
    "\n",
    "\n",
    "    #Likelihood calculation\n",
    "    \n",
    "    def logp(self, **params_values):       \n",
    "        \n",
    "        #For allocating the monopole values and cov valued\n",
    "\n",
    "        PMonopoleBineado = np.zeros((7, len(self.ks)))\n",
    "        CovBineado = np.zeros((7, len(self.ks)))\n",
    "\n",
    "        #PMonopoleBineado and CovBineado are equal to the values given by the self.monopole\n",
    "        PMonopoleBineado[0, :len(self.ks)],CovBineado[0, :len(self.ks)] = self.monopole(**params_values)\n",
    "        \n",
    "        #Likelihood is constructed, with j being the z-array value, and i the k-array value.\n",
    "        #Now we work with just j=0, corresponding to the first z-bin 1.7\n",
    "\n",
    "        #-Log Likelihood similar to an chi^2. \n",
    "        #def lnlikeSinSumar(j,i):\n",
    "            #return (PMonopoleBineado[j][i] - data['pkz'][0][i])**2 * 1/CovBineado[j][i]+ np.log(CovBineado[j][i])\n",
    "            #return (PMonopoleBineado[j][i] - data['pkz'][0][i])**2 * 1/CovBineado[j][i] + np.log(CovBineado[j][i])\n",
    "\n",
    "\n",
    "        #Indices in which we sum over the likelihood values. We use all of them\n",
    "        #IndicesLikelihood = np.arange(0,len(self.ks),1)\n",
    "\n",
    "        #Final likelihood value. Include the factor 2\n",
    "        #lnlike = -np.sum(lnlikeSinSumar(0,IndicesLikelihood))/2\n",
    "        \n",
    "        #return lnlike\n",
    "\n",
    "        lnlike = 0.0\n",
    "        for i in range(len(KArray)):\n",
    "            lnlike = lnlike + ((PMonopoleBineado[0][i] - data['pkz'][0][i])**2 *1/CovBineado[0][i] + np.log(CovBineado[0][i]))\n",
    "                 \n",
    "        lnlike = lnlike / 2\n",
    "\n",
    "        return -lnlike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input given to Cobaya. These are the cosmological parameters it will interpret. It fixed, like a CAMB with fixed cosmology\n",
    "\n",
    "# We define the dictionary 'info' including all our information, including the likelihood, theory (with the monopole)\n",
    "# and the priors\n",
    "\n",
    "    \n",
    "info = {\n",
    "    'debug': False,                        # Allow debugging\n",
    "    'likelihood': {'jpass': Pklike},       # Link likelihood (name: jpass) with the previously defined class\n",
    "    'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "               'my_pk': NodesInPrimordialPk},      # Include the primordial Pk with nodes in the theory class\n",
    "\n",
    "    'params': {\n",
    "        # Fixed cosmological parameters\n",
    "        'tau': tauJPAS, 'mnu': mnuJPAS, 'nnu': nmuJPAS, 'x1': 0.0, 'x4': 1.0,\n",
    "        'ombh2': OmegabJPASh2, 'omch2': OmegaCDMJPASh2, 'H0': H0JPAS,\n",
    "           \n",
    "        # Parameters of the nodes, with flat priors\n",
    "        'y1': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'proposal': 0.001, 'latex': 'y_1'},\n",
    "        'y2': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'proposal': 0.001, 'latex': 'y_2'},\n",
    "        'y3': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'proposal': 0.001, 'latex': 'y_3'},\n",
    "        'y4': {'prior': {'min': -23, 'max': -19}, 'ref': -20, 'proposal': 0.001, 'latex': 'y_4'},\n",
    "        'x2': {'prior': {'min': 0.0, 'max': 1.0}, 'ref': 0.5, 'proposal': 0.001, 'latex': 'x_2'},\n",
    "        'x3': {'prior': {'min': 0.0, 'max': 1.0}, 'ref': 0.5, 'proposal': 0.001, 'latex': 'x_3'}\n",
    "    },\n",
    "    \n",
    "    'prior': {\n",
    "        # Sorting criteria\n",
    "        'sorting': 'lambda x2, x3: x3 > x2'\n",
    "    },\n",
    "    \n",
    "    'sampler': {\n",
    "        \"polychord\": {\n",
    "            \"nlive\": 100,\n",
    "            \"precision_criterion\": 1e-3\n",
    "        }\n",
    "    }\n",
    "}\n",
    "               \n",
    "        #'sampler': {\n",
    "            #'evaluate': {\n",
    "                #'override': {\n",
    "                   #'P1': 2.2e-9, 'P2': 2.0e-9, 'ombh2': OmegabJPASh2Fid, 'omch2': OmegaCDMJPASFid, 'H0': hJPASFid*100}}}\n",
    "       #}\n",
    "\n",
    "#info['prior'] = {'sorting': 'x2, x3: x3>x2'}\n",
    "\n",
    "\n",
    "#Path for output folder and name of files\n",
    "\n",
    "#info[\"output\"] = \"/gpfs/users/martinezg/OutputCobaya/3NodesResults\"\n",
    "info[\"output\"] = \"/Users/guillermo/Desktop/FuncionaComoCosmoChord4NodosOrden/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] *WARNING* Ignored blocks/options: ['sampler', 'output']\n",
      "[prior] *WARNING* External prior 'sorting' loaded. Mind that it might not be normalized!\n",
      "[camb] `camb` module loaded successfully from /Users/guillermo/Desktop/code/CAMB/camb\n"
     ]
    }
   ],
   "source": [
    "#Cobaya interface\n",
    "\n",
    "#A model is constructed with the 'info' dictionary\n",
    "from cobaya.model import get_model     \n",
    "model = get_model(info)          \n",
    "\n",
    "#Parameters to evaluate the log posterior\n",
    "fixed_values = {'tau': tauJPAS, 'mnu': mnuJPAS, 'nnu': nmuJPAS, 'x1': 0.0 ,\n",
    "                'x2': (np.log(KArray[54]) - np.log(KArray[0])) / ((np.log(KArray[-1])-np.log(KArray[0]) )),\n",
    "                'x3': (np.log(KArray[100]) - np.log(KArray[0])) / ((np.log(KArray[-1])-np.log(KArray[0]) )),\n",
    "                'x4': 1.0,\n",
    "    'y1': np.log(PrimordialPowerLaw(AsJPAS,nsJPAS,KArray[0])),\n",
    "                'y2': np.log(PrimordialPowerLaw(AsJPAS,nsJPAS,KArray[54])),\n",
    "                'y3': np.log(PrimordialPowerLaw(AsJPAS,nsJPAS,KArray[100])),\n",
    "    'y4': np.log(PrimordialPowerLaw(AsJPAS,nsJPAS,KArray[-1])), \n",
    "                #'P3': 1.953070482409567e-09,\n",
    "    'H0': H0JPAS, 'ombh2': OmegabJPASh2,\n",
    "    'omch2': OmegaCDMJPASh2}\n",
    "\n",
    "model.logposterior(fixed_values)         \n",
    "\n",
    "camb_results = model.provider.get_CAMBdata();  #Results of CAMB from Cobaya interface\n",
    "\n",
    "pk_matter_Cobaya = model.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False) #Results of Pm from Cobaya interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Execute in Notebook. \n",
    "\n",
    "#from cobaya import run\n",
    "#updated_info, sampler = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
