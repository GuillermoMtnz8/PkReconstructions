{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to be loaded. Probably there are duplicated or missing ones\n",
    "import cobaya\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "import camb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmological parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constantes cosmológicas:\n",
    "c = 2.99792458E5;   HJPAS = 1/(c/100);\n",
    "\n",
    "#Parámetros que no se van a samplear:\n",
    "gamma = 0.545; OmegakJPAS = 0; AsJPAS = 2.09052E-9; nsJPAS = 0.9626; \n",
    "\n",
    "#Parámetros cosmológicos directos:\n",
    "hJPASFid = 0.6736; OmegabJPASh2Fid = 0.02237; OmegaCDMJPASh2Fid = 0.1200; \n",
    "OmegamJPASFid = 0.3153;\n",
    "\n",
    "#Parámetros cosmológicos indirectos:\n",
    "OmegabJPASFid = OmegabJPASh2Fid/hJPASFid**2; OmegaCDMJPASFid = OmegaCDMJPASh2Fid/hJPASFid**2;\n",
    "OmegaLJPASFid = 1 - OmegamJPASFid;\n",
    "\n",
    "#Parámetros cosmológicos fuera del fiducial:\n",
    "hJPAS = hJPASFid + hJPASFid/100;\n",
    "OmegabJPASh2 = OmegabJPASh2Fid + OmegabJPASh2Fid/100;\n",
    "OmegaCDMJPASh2 = OmegaCDMJPASh2Fid + OmegaCDMJPASh2Fid/100; \n",
    "OmegamJPAS = OmegamJPASFid + OmegamJPASFid/100;\n",
    "\n",
    "#Parámetros cosmológicos indirectos fuera del fiducial:\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2; OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;\n",
    "OmegaLJPAS = 1 - OmegamJPAS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros del Fiducial obtenidos con CAMB:\n",
    "OmegamFid = 0.31417\n",
    "\n",
    "#En z = 1.7\n",
    "EzFid = 2.6210003\n",
    "XiFid = 3263.07985798\n",
    "DaFid = 1208.54809555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k and z binning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bineado de k y de z\n",
    "#Límites y pasos de los arrays. Escalas en unidades de h.\n",
    "kminKArrayCompleto = 0.001;   kmaxKArrayCompleto = 2.4900;  pasoKArrayCompleto = 0.025;\n",
    "zmin = 1.7;   zmax = 2.9;   pasoz = 0.2;\n",
    "\n",
    "#Bines de k, completos y reducidos\n",
    "KArrayCompleto = np.exp(np.arange(math.log(kminKArrayCompleto), math.log(kmaxKArrayCompleto), pasoKArrayCompleto) )\n",
    "KArray = KArrayCompleto[range(121,246)]\n",
    "\n",
    "#Bines de k por arriba y por abajo\n",
    "KArrayUpper = np.zeros(len(KArray)); KArrayLower = np.zeros(len(KArray));\n",
    "\n",
    "for i in range(0, len(KArray)-1):\n",
    "    KArrayUpper[i] = KArray[i] + (KArray[i+1]-KArray[i])/2;   KArrayLower[i] = KArray[i] - (KArray[i+1]-KArray[i])/2;\n",
    "\n",
    "KArrayUpper[-1] = KArrayUpper[-2];  KArrayLower[-1] = KArrayLower[-2];\n",
    "\n",
    "#Bines de z:\n",
    "zaAntes = np.arange(zmin-0.1, zmax+pasoz/2, pasoz)\n",
    "zaAdicional = np.array([0])\n",
    "zaConBines = np.arange(zmin-pasoz/2, zmax+0.01+pasoz/2, pasoz/2)\n",
    "za = np.concatenate((zaAdicional,zaConBines))\n",
    "positions_Upper = [3, 5, 7, 9, 11, 13, 15]\n",
    "positions_Lower = [1, 3, 5, 7, 9, 11, 13]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(k) data and densities reading #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pkz', 'ndz'])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a class to read the simulated data specifying the path as input\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    Simulated_pk_filename = path_to_data+'FicticioHighZArrayEnK.dat'\n",
    "    Simulated_densities = path_to_data+'DensityHighZ.dat'\n",
    "\n",
    "    data['pkz'] = np.zeros((len(zaAntes), len(KArray)))\n",
    "    data['ndz'] = np.zeros(len(zaAntes))\n",
    "  \n",
    "    with open(Simulated_pk_filename) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['pkz'][0][i] = float(line[2])\n",
    "            data['pkz'][1][i] = float(line[3])\n",
    "            data['pkz'][2][i] = float(line[4])\n",
    "            data['pkz'][3][i] = float(line[5])\n",
    "            data['pkz'][4][i] = float(line[6])\n",
    "            data['pkz'][5][i] = float(line[7])\n",
    "            data['pkz'][6][i] = float(line[8])\n",
    "\n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(zaAntes)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Read data se convierte en un diccionario\n",
    "data = read_data('/Users/guillermo/Desktop/')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMB settings and results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    }
   ],
   "source": [
    "# Let's try to obtain a PPS and Pm with nodes when using CAMB\n",
    "\n",
    "#Se dan los valores de los nodos\n",
    "nodes_log_k = [np.log(KArray[0]), np.log(KArray[-1])]\n",
    "nodes_log_PPS = [2.3, 3.1]\n",
    "\n",
    "#Se deshace la escala log\n",
    "nodes_k = np.exp(nodes_log_k)\n",
    "nodes_PPS = np.exp(nodes_log_PPS)*1e-10\n",
    "\n",
    "#Aquí se interpolan los nodos (si sonlo son 2, el tipo debe ser lineal)\n",
    "func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  #Este comando interpola entre columnas\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "\n",
    "#Set de parámetros para CAMB 'pars', con su comología, su primordial modificado y su p de materia modificado con nodos\n",
    "from camb import model\n",
    "\n",
    "pars = camb.CAMBparams()\n",
    "pars.InitPower = camb.initialpower.SplinedInitialPower()\n",
    "pars.set_cosmology(H0=hJPAS*100, ombh2=OmegabJPASh2, omch2=OmegaCDMJPASh2, mnu=0.0, omk=OmegakJPAS, tau=0.06)\n",
    "pars.InitPower.set_scalar_log_regular(KArray[0], KArray[-1], func(KArray))\n",
    "pars.set_matter_power(redshifts=za, kmax=KArrayCompleto[-1])\n",
    "pars.NonLinear = model.NonLinear_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultados de CAMB con los nodos incorporados. Generamos un P de materia y calculamos, por ejemplo sigma8\n",
    "results = camb.get_results(pars) #Resultados de CAMB\n",
    "\n",
    "#P de materia\n",
    "kh, z, pk = results.get_matter_power_spectrum(minkh=KArrayCompleto[0], maxkh=KArrayCompleto[-1], npoints = len(KArrayCompleto))\n",
    "\n",
    "#Sigma8\n",
    "s8 = np.array(results.get_sigma8())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to interface with Cobaya #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume this method above is ok, so I will now create the classes to interface with Cobaya\n",
    "# I will create a cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes\n",
    "\n",
    "#Se crean las clases para interactuar con Cobaya: NodesInPrimordialPk (teoría) y Pklike (likelihood)\n",
    "\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase con la teoría, es decir, con la modificación del Primordial para incluir nuestros nodos\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Iniciar self con un array de k\n",
    "        self.ks = KArray\n",
    "\n",
    "    #Parece que aquí apodamos a las variables de los nodos por sus nombres: k1, k2... pk1, pk2...\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict):\n",
    "        \n",
    "        pivot_scalar = 0.05   #Valor del pivote\n",
    "        nodes_k = [params_values_dict['k1'], params_values_dict['k2']] #Nombre nodos eje x\n",
    "        nodes_PPS = [params_values_dict['P1'], params_values_dict['P2']] #nombre nodos eje y\n",
    "        \n",
    "        #Se interpolan estos nodos.\n",
    "        Pk_func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  # interpolate along columns\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "        \n",
    "        #Construimos el PPS(k) en todas las escalas\n",
    "        state['primordial_scalar_pk'] = {'kmin': self.ks[0], 'kmax': self.ks[-1],\n",
    "                                         'Pk': Pk_func(self.ks), 'log_regular': True}\n",
    "\n",
    "    #Metemos en una función el PPS para poder evaluarla \n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "   \n",
    "    #Función que retorna los parámetros de los nodos\n",
    "    def get_can_support_params(self):\n",
    "        return ['k1', 'k2', 'P1', 'P2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase con el likelihood. Aquí tendremos que introducir nuestro modelo y el cálculo del likelihood\n",
    "\n",
    "class Pklike(Likelihood): #Se define la clase.\n",
    "    \n",
    "    def initialize(self):  \n",
    "\n",
    "        #Path en el que están los datos. Llamamos a read_data\n",
    "        self.data = read_data('/Users/guillermo/Desktop/')\n",
    "\n",
    "        # Se da un grid de zs con extremos en nuestros bines y 150 pasos\n",
    "        # If you need some quantities at z = 0 you need to have z_win also at zero, please change accordantly\n",
    "        self.z_win = zaAntes\n",
    "        self.z_winCompleto = za\n",
    "\n",
    "   \n",
    "    #¿Por qué es necesario tener requisitos? ¿No puedo llamar a funciones de CAMB sin antes incluirlas aquí?\n",
    "    \n",
    "    def get_requirements(self):\n",
    "        \n",
    "        return {'omegam': None,                 \n",
    "                'Pk_interpolator': {'z': self.z_winCompleto, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_winCompleto},\n",
    "                'angular_diameter_distance': {'z': self.z_winCompleto},\n",
    "                'Hubble': {'z': self.z_winCompleto, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_winCompleto},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    "\n",
    "   \n",
    "    #Aquí defino el monopolo\n",
    "    \n",
    "    def monopole(self, **params_dic):\n",
    "\n",
    "        results = self.provider.get_CAMBdata()   #Parece que esto lee los datos de CAMB\n",
    "             \n",
    "        # Aquí se puede acceder al PPS\n",
    "        ks = KArray\n",
    "        pps = results.Params.scalar_power(ks)       \n",
    "        \n",
    "        #Aquí creamos todas las funciones y variables necesarias para generar el P Kaiser.\n",
    "        Omegam = self.provider.get_param('omegam');  \n",
    "        Ez = np.sqrt( Omegam*(1+self.z_winCompleto)**3+(1-Omegam) ); \n",
    "        H = HJPAS * Ez\n",
    "        f = (Omegam*(1+self.z_winCompleto)**3*1/(Ez**2))**gamma\n",
    "        sigma8z0 = self.provider.get_sigma8_z(self.z_winCompleto[0])\n",
    "        DeReves = self.provider.get_sigmaR_z(8,self.z_winCompleto)/self.provider.get_sigmaR_z(8,self.z_winCompleto[0])\n",
    "        De = DeReves[::-1]\n",
    "        \n",
    "        def bJPAS(z):\n",
    "          return 0.53+0.289*(1+z)**2\n",
    "            \n",
    "        A = De*bJPAS(za)*sigma8z0\n",
    "        R = De*f*sigma8z0\n",
    "\n",
    "        #Fotometría\n",
    "        DeltazJPAS = 0.00364236313918151\n",
    "        sigmar = DeltazJPAS*(1+self.z_winCompleto)/H\n",
    "\n",
    "        # This is the matter power spectrum interpolator:\n",
    "        pk = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)   #Parece que aquí se obtiene el Pmateria\n",
    "        pk_delta = pk.P(ks, self.z_winCompleto)         # pk_delta is an array de pmateria evaluado en ks and zs\n",
    "\n",
    "        \n",
    "        #Fingers of God\n",
    "        sigmap = (1/(6*np.pi**2)*(De/1)**2*integrate.quad(lambda k:  pk.P(k, self.z_winCompleto[2]) , ks[0], ks[-1])**0.5)\n",
    "\n",
    "        def FFoG(mu,k):\n",
    "            return 1/(1+(f[2]*k*mu*sigmap)**2)\n",
    "\n",
    "        \n",
    "        #Efecto AP\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_winCompleto)*hJPAS;\n",
    "        DA = Xi/(1+self.z_winCompleto);\n",
    "        \n",
    "        FactorAP = DAFid**2*Ez[0]/( DA[0]**2*EzFid )\n",
    "\n",
    "        def Q(mu):\n",
    "            return ((Ez[2]**2*Xi[2]**2*mu**2-EzFid**2*XiFid**2*(mu**2-1))**0.5/(EzFid*Xi[2]))\n",
    " \n",
    "        def muObs(mu):\n",
    "            return mu*Ez[2]/(EzFid*Q(mu))\n",
    "           \n",
    "        def kObs(mu,k):\n",
    "            return Q(mu)*k \n",
    "\n",
    "        #P de galaxias final\n",
    "        def Pg(mu,k):\n",
    "            return FactorAP*FFog(muObs(mu),kObs(mu,k))*(A[2]+R[2]*muObs(mu)**2)**2 * PmatInterCAMB(kObs(mu,k))/sigma8z0**2 *np.exp(-(k*mu*sigmar[2])**2)\n",
    "\n",
    "        #Se usa la regla del trapecio con 2000 pasos\n",
    "        def Pgmonopole(k):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 1/2 * integrate.trapz(Pg(mu, k), mu)\n",
    "            \n",
    "        PgmonopoleValores = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "             PgmonopoleValores[i] = Pgmonopole(ks[i])\n",
    "\n",
    "        #Covarianza\n",
    "        \n",
    "        #Densidades desde data. #DensityHighZ es equivalente a self.data['ndz]\n",
    "\n",
    "        #Definición del volumen (requiere distancia angular con unidades y binear en zupper y zlower)\n",
    "        #Área del cielo\n",
    "        fsky = 0.2575;\n",
    "\n",
    "        #Bines de z por arriba y por abajo:\n",
    "\n",
    "        #Distancia angular para los bines z upper y lower:\n",
    "\n",
    "        XiZaLower = self.provider.get_comoving_radial_distance(self.z_winCompleto[positions_Lower])*hJPAS\n",
    "        XiZaUpper = self.provider.get_comoving_radial_distance(self.z_winCompleto[positions_Upper])*hJPAS\n",
    "\n",
    "        \n",
    "        #Definición de volumen:\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "\n",
    "        #Definición del número de modos\n",
    "\n",
    "        #Número de modos. Depende de las variables k1 y k2, que debe corresponderse a kupper y klower\n",
    "        def Nk(k1,k2):\n",
    "            return Vol[0] * (4*np.pi/3*(k1**3-k2**3))/((2*np.pi)**3)\n",
    "\n",
    "        #Evaluamos Nk para cada valor de nuestro array de k\n",
    "        NkEvaluado = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "            NkEvaluado[i] = Nk(KArrayUpper[i],KArrayLower[i])\n",
    "\n",
    "        #Definición de la covarianza\n",
    "\n",
    "        #Va a depender de k1 y k2. No me gusta mucho:\n",
    "        def Cov(k,k1,k2):\n",
    "            return 2 * (Pgmonopole(k) + 1/self.data['ndz'][0])**2 / Nk(k1,k2)\n",
    "\n",
    "        #Evaluamos Cov para nuestros k\n",
    "        CovEvaluado = 2 *(PgmonopoleValores + 1/self.data['ndz'][0])**2 / NkEvaluado\n",
    "\n",
    "        \n",
    "        return PgmonopoleValores\n",
    "\n",
    "\n",
    "    #Aquí calculo el likelihood\n",
    "    \n",
    "    def logp(self, **params_values):       \n",
    "        \n",
    "        # Calcular el monopolo:\n",
    "        \n",
    "        Pk = self.monopole(**params_values)    #Del anterior código. ¿Debo llamar al monopolo así o con PgmonopoleValores[i]?\n",
    "        \n",
    "        # Calcular el loglikelihood\n",
    "        #Bineamos el P(k) para cuando entre al likelihood:\n",
    "        PgBineadoz1 = np.zeros(len(ks)); PgBineadoz2 = np.zeros(len(ks));\n",
    "        PgBineadoz3 = np.zeros(len(ks)); PgBineadoz4 = np.zeros(len(ks));\n",
    "        PgBineadoz5 = np.zeros(len(ks)); PgBineadoz6 = np.zeros(len(ks));\n",
    "        PgBineadoz7 = np.zeros(len(ks));\n",
    "\n",
    "        PgBineado = np.array([PgBineadoz1,PgBineadoz2,PgBineadoz3,PgBineadoz4,PgBineadoz5,PgBineadoz6,PgBineadoz7])\n",
    "\n",
    "        for i in range(0, len(ks)):\n",
    "            PgBineado[0][i] = PgmonopoleValores[i]\n",
    "\n",
    "        #Bineamos la covarianza para cuando entre al likelihood\n",
    "        CovBineadoz1 = np.zeros(len(ks)); CovBineadoz2 = np.zeros(len(ks));\n",
    "        CovBineadoz3 = np.zeros(len(ks)); CovBineadoz4 = np.zeros(len(ks));\n",
    "        CovBineadoz5 = np.zeros(len(ks)); CovBineadoz6 = np.zeros(len(ks));\n",
    "        CovBineadoz7 = np.zeros(len(ks));\n",
    "\n",
    "        CovBineado = np.array([CovBineadoz1,CovBineadoz2,CovBineadoz3,CovBineadoz4,CovBineadoz5,CovBineadoz6,CovBineadoz7])\n",
    "\n",
    "        for i in range(0, len(ks)):\n",
    "            CovBineado[0][i] = CovEvaluado[i]\n",
    "\n",
    "        #Construimos el likelihood, siendo j el valor del array de z, i el valor del array de k:\n",
    "\n",
    "        #Este likelihood es similar a un chi^2. ¿Igual? ¿Factor del log del determinante = log cov?\n",
    "        def lnlikeSinSumar(j,i):\n",
    "            return (PgBineado[j][i]-data['pkz'][0][i])**2 * 1/CovBineado[j][i] + np.log(CovBineado[j][i])\n",
    "    \n",
    "        #índices en los que queremos evaluar el likelihood y el paso entre ellos. Usamos todos:\n",
    "        IndicesLikelihood = np.arange(0,len(ks),1)\n",
    "\n",
    "        #Likelihood sumando a los índices\n",
    "        lnlike = np.sum(lnlikeSinSumar(0,IndicesLikelihood))\n",
    "        lnlike\n",
    "        return lnlike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you pass input to Cobaya\n",
    "# Diccionario que le pasamos a Cobaya, donde linkamos con nuestros códigos de teoría y el likelihood.\n",
    "\n",
    "info = {'debug': True,                        #Esto permite obtener info de los errores\n",
    "        'likelihood': {'jpass': Pklike},      #Aquí se engancha el likelihood (nombre jpass) que hemos definido en la clase de arriba\n",
    "        'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "                   'my_pk': NodesInPrimordialPk},      #Aquí le pasamos nuestra clase de teoría, con nombre \"my_pk\".\n",
    "       'params': {\n",
    "        # Parámetros cosmológicos fijados\n",
    "        'tau': 0.06, 'mnu': 0.00, 'nnu': 3.046,\n",
    "        # Parámetros nodales, flat priors\n",
    "        'P1': {'prior': {'min': 1e-10, 'max': 5.6e-9}, 'latex': 'P_1'},\n",
    "        'P2': {'prior': {'min': 1e-10, 'max': 5.6e-9}, 'latex': 'P_2'},\n",
    "        # Parámetros cosmológicos a samplear. Loc y scale son, en prior gaussiano, valor medio y desviación estandar.\n",
    "        'ombh2': {'prior': {'dist': 'norm', 'loc': OmegabJPASh2Fid, 'scale': 0.00015}, 'latex': 'Omega_bh^2'},\n",
    "        'omch2': {'prior': {'dist': 'norm', 'loc': OmegaCDMJPASFid, 'scale': 0.0012}, 'latex': 'Omega_ch^2'},\n",
    "        'H0': {'prior': {'dist': 'norm', 'loc': hJPASFid*100, 'scale': 0.54}, 'latex': 'H_0'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2024-01-18 10:06:59,352 [model] Input info updated with defaults (dumped to YAML):\n",
      "theory:\n",
      "  camb:\n",
      "    version: null\n",
      "    path: null\n",
      "    speed: 0.3\n",
      "    stop_at_error: false\n",
      "    extra_args: null\n",
      "    ignore_obsolete: false\n",
      "    use_renames: false\n",
      "    external_primordial_pk: true\n",
      "    renames:\n",
      "      omegabh2: ombh2\n",
      "      omegach2: omch2\n",
      "      omegal: omega_de\n",
      "      omegak: omk\n",
      "      yhe: YHe\n",
      "      yheused: YHe\n",
      "      YpBBN: Y_p\n",
      "  my_pk:\n",
      "    speed: -1\n",
      "    stop_at_error: false\n",
      "    version: null\n",
      "    external: !!python/name:__main__.NodesInPrimordialPk ''\n",
      "likelihood:\n",
      "  jpass:\n",
      "    type: []\n",
      "    speed: -1\n",
      "    stop_at_error: false\n",
      "    version: null\n",
      "    external: !!python/name:__main__.Pklike ''\n",
      "params:\n",
      "  tau:\n",
      "    value: 0.06\n",
      "  mnu:\n",
      "    value: 0.0\n",
      "  nnu:\n",
      "    value: 3.046\n",
      "  P1:\n",
      "    prior:\n",
      "      min: 1.0e-10\n",
      "      max: 5.6e-09\n",
      "    latex: P_1\n",
      "  P2:\n",
      "    prior:\n",
      "      min: 1.0e-10\n",
      "      max: 5.6e-09\n",
      "    latex: P_2\n",
      "  ombh2:\n",
      "    prior:\n",
      "      dist: norm\n",
      "      loc: 0.02237\n",
      "      scale: 0.00015\n",
      "    latex: Omega_bh^2\n",
      "    renames:\n",
      "    - omegabh2\n",
      "  omch2:\n",
      "    prior:\n",
      "      dist: norm\n",
      "      loc: 0.26447041034523616\n",
      "      scale: 0.0012\n",
      "    latex: Omega_ch^2\n",
      "    renames:\n",
      "    - omegach2\n",
      "  H0:\n",
      "    prior:\n",
      "      dist: norm\n",
      "      loc: 67.36\n",
      "      scale: 0.54\n",
      "    latex: H_0\n",
      "debug: true\n",
      "\n",
      " 2024-01-18 10:06:59,369 [camb] Attempting import of Cobaya-installed version, but defaulting to global import if not found.\n",
      " 2024-01-18 10:06:59,371 [camb] No (compiled) installation of 'camb' at /Users/guillermo/Desktop/code/code/CAMB: Could not find compiled CAMB library camblib.so in /Users/guillermo/Desktop/code/code/CAMB.\n",
      " 2024-01-18 10:06:59,372 [camb] Defaulting to global import.\n",
      " 2024-01-18 10:06:59,374 [camb] `camb` module loaded successfully from /Users/guillermo/Desktop/code/CAMB/camb\n",
      " 2024-01-18 10:06:59,383 [model] Parameters were assigned as follows:\n",
      " 2024-01-18 10:06:59,383 [model] - jpass:\n",
      " 2024-01-18 10:06:59,387 [model]      Input:  []\n",
      " 2024-01-18 10:06:59,389 [model]      Output: []\n",
      " 2024-01-18 10:06:59,392 [model] - camb.transfers:\n",
      " 2024-01-18 10:06:59,393 [model]      Input:  ['tau', 'mnu', 'nnu', 'ombh2', 'omch2', 'H0']\n",
      " 2024-01-18 10:06:59,394 [model]      Output: []\n",
      " 2024-01-18 10:06:59,395 [model] - camb:\n",
      " 2024-01-18 10:06:59,403 [model]      Input:  []\n",
      " 2024-01-18 10:06:59,408 [model]      Output: []\n",
      " 2024-01-18 10:06:59,409 [model] - my_pk:\n",
      " 2024-01-18 10:06:59,411 [model]      Input:  ['P1', 'P2']\n",
      " 2024-01-18 10:06:59,411 [model]      Output: []\n",
      " 2024-01-18 10:06:59,419 [model] Components will be computed in the order:\n",
      " 2024-01-18 10:06:59,420 [model]  - [camb.transfers, my_pk, camb, jpass]\n",
      " 2024-01-18 10:06:59,422 [model] Requirements will be calculated by these components:\n",
      " 2024-01-18 10:06:59,423 [model] - omegam: camb\n",
      " 2024-01-18 10:06:59,424 [model] - Pk_interpolator: camb\n",
      " 2024-01-18 10:06:59,425 [model] - comoving_radial_distance: camb\n",
      " 2024-01-18 10:06:59,426 [model] - angular_diameter_distance: camb\n",
      " 2024-01-18 10:06:59,427 [model] - Hubble: camb\n",
      " 2024-01-18 10:06:59,428 [model] - sigma8_z: camb\n",
      " 2024-01-18 10:06:59,428 [model] - CAMBdata: camb\n",
      " 2024-01-18 10:06:59,430 [model] - CAMB_transfers: camb.transfers\n",
      " 2024-01-18 10:06:59,431 [model] - primordial_scalar_pk: my_pk\n",
      " 2024-01-18 10:06:59,433 [parameterization] *ERROR* The following expected sampled parameters (or their aliases) were not found : {'ombh2': ['omegabh2'], 'omch2': ['omegach2'], 'P1': [], 'H0': [], 'P2': []}\n"
     ]
    },
    {
     "ename": "LoggedError",
     "evalue": "The following expected sampled parameters (or their aliases) were not found : {'ombh2': ['omegabh2'], 'omch2': ['omegach2'], 'P1': [], 'H0': [], 'P2': []}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLoggedError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[277], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcobaya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model     \n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(info)          \u001b[38;5;66;03m#Se construye un modelo con el diccionario info\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      9\u001b[0m camb_results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprovider\u001b[38;5;241m.\u001b[39mget_CAMBdata();\n\u001b[1;32m     11\u001b[0m pk \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprovider\u001b[38;5;241m.\u001b[39mget_Pk_interpolator((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_tot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_tot\u001b[39m\u001b[38;5;124m'\u001b[39m), nonlinear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cobaya/model.py:534\u001b[0m, in \u001b[0;36mModel.logposterior\u001b[0;34m(self, params_values, as_dict, make_finite, return_derived, cached, _no_check)\u001b[0m\n\u001b[1;32m    532\u001b[0m     params_values_array \u001b[38;5;241m=\u001b[39m params_values\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     params_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameterization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_sampled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     params_values_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_sampled_array(params_values)\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_debug():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cobaya/parameterization.py:326\u001b[0m, in \u001b[0;36mParameterization.check_sampled\u001b[0;34m(self, sampled_params)\u001b[0m\n\u001b[1;32m    324\u001b[0m     sampled_params \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sampled_params, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_sampled_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msampled_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sampled_params) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampled):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cobaya/parameterization.py:362\u001b[0m, in \u001b[0;36mParameterization.check_sampled_dict\u001b[0;34m(self, **sampled_params)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following expected sampled parameters \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwere not found : \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m                {p: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampled_renames[p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m not_found})\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LoggedError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog, \u001b[38;5;241m*\u001b[39mmsg)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Ignore fixed input parameters if they have the correct value\u001b[39;00m\n\u001b[1;32m    364\u001b[0m not_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sampled_params)\n",
      "\u001b[0;31mLoggedError\u001b[0m: The following expected sampled parameters (or their aliases) were not found : {'ombh2': ['omegabh2'], 'omch2': ['omegach2'], 'P1': [], 'H0': [], 'P2': []}"
     ]
    }
   ],
   "source": [
    "# Let's reproduce the same matter power spectrum as the one by single camb through the cobaya interface\n",
    "# Se reproduce el Pmateria construido por CAMB con la interfaz de Cobaya:\n",
    "\n",
    "from cobaya.model import get_model     \n",
    "model = get_model(info)          #Se construye un modelo con el diccionario info\n",
    "\n",
    "model.logposterior({}) \n",
    "\n",
    "camb_results = model.provider.get_CAMBdata();\n",
    "\n",
    "pk = model.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
