{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to be loaded. Probably there are duplicated or missing ones\n",
    "import cobaya\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "import camb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmological parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosmological constants\n",
    "c = 2.99792458E5;   HJPAS = 1/(c/100);\n",
    "\n",
    "#Parameteres that won't be sampled\n",
    "gamma = 0.545; OmegakJPAS = 0; AsJPAS = 2.09052E-9; nsJPAS = 0.9626; \n",
    "\n",
    "#Direct cosmological parameters of the fiducial cosmology\n",
    "hJPASFid = 0.6736; OmegabJPASh2Fid = 0.02237; OmegaCDMJPASh2Fid = 0.1200; \n",
    "OmegamJPASFid = 0.3153;\n",
    "\n",
    "#Indirect cosmological parameters of the fiducial cosmology\n",
    "OmegabJPASFid = OmegabJPASh2Fid/hJPASFid**2; OmegaCDMJPASFid = OmegaCDMJPASh2Fid/hJPASFid**2;\n",
    "OmegaLJPASFid = 1 - OmegamJPASFid;\n",
    "\n",
    "#Cosmological parameters outside the fiducial cosmology\n",
    "hJPAS = hJPASFid + hJPASFid/100;\n",
    "OmegabJPASh2 = OmegabJPASh2Fid + OmegabJPASh2Fid/100;\n",
    "OmegaCDMJPASh2 = OmegaCDMJPASh2Fid + OmegaCDMJPASh2Fid/100; \n",
    "OmegamJPAS = OmegamJPASFid + OmegamJPASFid/100;\n",
    "\n",
    "#Indirect cosmological parameters outside the fiducial\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2; OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;\n",
    "OmegaLJPAS = 1 - OmegamJPAS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiducial cosmology functions and constants\n",
    "OmegamFid = 0.31417\n",
    "\n",
    "#At z=1.7 (first bin)\n",
    "EzFid = 2.6210003\n",
    "XiFid = 3263.07985798\n",
    "DAFid = 1208.54809555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k and z binning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays limits and steps. In h units\n",
    "kminKArrayCompleto = 0.001;   kmaxKArrayCompleto = 2.4900;  pasoKArrayCompleto = 0.025;\n",
    "zmin = 1.7;   zmax = 2.9;   pasoz = 0.2;\n",
    "\n",
    "#k binning, complete and in a reduced scaleset\n",
    "KArrayCompleto = np.exp(np.arange(math.log(kminKArrayCompleto), math.log(kmaxKArrayCompleto), pasoKArrayCompleto) )\n",
    "KArray = KArrayCompleto[range(121,246)]\n",
    "\n",
    "#k binning on lower and upper limits\n",
    "KArrayUpper = np.zeros(len(KArray)); KArrayLower = np.zeros(len(KArray));\n",
    "\n",
    "for i in range(0, len(KArray)-1):\n",
    "    KArrayUpper[i] = KArray[i] + (KArray[i+1]-KArray[i])/2;   KArrayLower[i] = KArray[i] - (KArray[i+1]-KArray[i])/2;\n",
    "\n",
    "KArrayUpper[-1] = KArrayUpper[-2];  KArrayLower[-1] = KArrayLower[-2];\n",
    "\n",
    "\n",
    "#z binning\n",
    "\n",
    "#Original one\n",
    "zaAntes = np.arange(zmin-0.1, zmax+pasoz/2, pasoz)\n",
    "\n",
    "#Including z=0\n",
    "zaAdicional = np.array([0])\n",
    "\n",
    "#Binning including all lower and upper z-bins limits\n",
    "zaConBines = np.arange(zmin-pasoz/2, zmax+0.01+pasoz/2, pasoz/2)\n",
    "\n",
    "#z binning\n",
    "za = np.concatenate((zaAdicional,zaConBines))\n",
    "\n",
    "#Positions of upper and lower limits of the z-bins in the za array\n",
    "positions_Upper = [3, 5, 7, 9, 11, 13, 15]\n",
    "positions_Lower = [1, 3, 5, 7, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(k) data and densities reading #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pkz', 'ndz'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a class to read the simulated data specifying the path as input\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    Simulated_pk_filename = path_to_data+'Pk_Simulated_Data_HighZ_NoFeature.dat'\n",
    "    Simulated_densities = path_to_data+'Densities_HighZ.dat'\n",
    "\n",
    "    data['pkz'] = np.zeros((len(zaAntes), len(KArray)))\n",
    "    data['ndz'] = np.zeros(len(zaAntes))\n",
    "  \n",
    "    with open(Simulated_pk_filename) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['pkz'][0][i] = float(line[2])\n",
    "            data['pkz'][1][i] = float(line[3])\n",
    "            data['pkz'][2][i] = float(line[4])\n",
    "            data['pkz'][3][i] = float(line[5])\n",
    "            data['pkz'][4][i] = float(line[6])\n",
    "            data['pkz'][5][i] = float(line[7])\n",
    "            data['pkz'][6][i] = float(line[8])\n",
    "\n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(zaAntes)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Read data is converted in the dictionary 'data'\n",
    "data = read_data('/Users/guillermo/Desktop/')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMB settings and results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    }
   ],
   "source": [
    "# Let's try to obtain a PPS and Pm with nodes using CAMB\n",
    "\n",
    "#Nodes value test\n",
    "nodes_log_k = [np.log(KArray[0]), np.log(KArray[-1])]\n",
    "nodes_log_PPS = [2.1293593469628953, 1.8962555118848632]\n",
    "\n",
    "#Undo the logs\n",
    "nodes_k = np.exp(nodes_log_k)\n",
    "nodes_PPS = np.exp(nodes_log_PPS)*1e-10\n",
    "\n",
    "#Node interpolation. With just 2, kind always linear\n",
    "func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  #This command interpolates among columns\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "\n",
    "\n",
    "#Parameter set 'pars' for CAMB, with its cosmology, a modified PPS and a P(m) including the nodes\n",
    "from camb import model\n",
    "\n",
    "pars = camb.CAMBparams()\n",
    "pars.InitPower = camb.initialpower.SplinedInitialPower()\n",
    "pars.set_cosmology(H0=hJPAS*100, ombh2=OmegabJPASh2, omch2=OmegaCDMJPASh2, mnu=0.0, omk=OmegakJPAS, tau=0.06)\n",
    "pars.InitPower.set_scalar_log_regular(KArrayCompleto[0], KArrayCompleto[-1], func(KArrayCompleto))\n",
    "pars.set_matter_power(redshifts=za, kmax=KArrayCompleto[-1])\n",
    "pars.NonLinear = model.NonLinear_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMB matter power spectrum Pm(k) with the nodes methodology included.\n",
    "\n",
    "results = camb.get_results(pars) #Resultados de CAMB\n",
    "kh, z, pk = results.get_matter_power_spectrum(minkh=KArrayCompleto[0], maxkh=KArrayCompleto[-1], npoints = len(KArrayCompleto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to interface with Cobaya #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If previous is OK, now the classes to interface with Cobaya are created.\n",
    "\n",
    "#A cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes are created\n",
    "\n",
    "#Needed packages\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class of the theory, with the PPS modification including the nodes\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Initialize self with the k-array\n",
    "        self.ks = KArray\n",
    "\n",
    "    #It seems that in here we allocate the values of the parameters to be sampled and definme their names\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict):\n",
    "        \n",
    "        pivot_scalar = 0.05   #k pivot value\n",
    "        \n",
    "        nodes_k = [params_values_dict['k1'], params_values_dict['k2']] \n",
    "        nodes_PPS = [params_values_dict['P1'], params_values_dict['P2']] \n",
    "\n",
    "        #I guess I can fixed the k nodes for the N=2 here\n",
    "        #nodes_k = [np.log(KArray[0]), np.log(KArray[-1])]\n",
    "        \n",
    "        #nodes_k and nodes_PPS are interpolated\n",
    "        Pk_func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  # interpolate along columns\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "        \n",
    "        #The PPS(k) is evaluated at our array of k\n",
    "        state['primordial_scalar_pk'] = {'kmin': KArray[0], 'kmax': KArray[-1],\n",
    "                                         'Pk': Pk_func(KArray), 'log_regular': True}\n",
    "\n",
    "    #To be able to evaluate the PPS?\n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "   \n",
    "    #Function that returns the nodes parameters values\n",
    "    def get_can_support_params(self):\n",
    "        return ['k1', 'k2', 'P1', 'P2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class incorporating the monopole and the likelihood. \n",
    "\n",
    "\n",
    "class Pklike(Likelihood): #Class is defined\n",
    "    \n",
    "    def initialize(self):  \n",
    "\n",
    "        #Path in wich the data are. We call read_data with this path.\n",
    "        self.data = read_data('/Users/guillermo/Desktop/')\n",
    "\n",
    "        #Grid of z to be employed\n",
    "        self.z_win = zaAntes\n",
    "        self.z_winCompleto = za\n",
    "        self.z_winExtended = np.linspace(0., 3, 100)\n",
    "        self.ks = KArray\n",
    "\n",
    "    \n",
    "    def get_requirements(self): #¿Por qué es necesario tener requisitos? ¿No puedo usar las funciones sin esto?\n",
    "        \n",
    "        return {'omegam': None,                 \n",
    "                'Pk_interpolator': {'z': self.z_winExtended, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_winCompleto},\n",
    "                'angular_diameter_distance': {'z': self.z_winCompleto},\n",
    "                'Hubble': {'z': self.z_winCompleto, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_winCompleto},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    "\n",
    "   \n",
    "    #Definition of the monopole\n",
    "    \n",
    "    def monopole(self, **params_dic):\n",
    "\n",
    "        results = self.provider.get_CAMBdata()   #CAMB results in results\n",
    "             \n",
    "        # Esta parte quizás la puedo omitir\n",
    "        ks = KArray\n",
    "        pps = results.Params.scalar_power(ks)       \n",
    "        \n",
    "        # All functions and variables to compute the Kaiser model\n",
    "        Omegam = self.provider.get_param('omegam')  \n",
    "        Ez = np.sqrt( Omegam*(1+self.z_winCompleto)**3+(1-Omegam) ); \n",
    "        H = HJPAS * Ez\n",
    "        f = (Omegam*(1+self.z_winCompleto)**3*1/(Ez**2))**gamma\n",
    "        sigma8z0 = self.provider.get_sigma8_z(self.z_winCompleto[0])\n",
    "        DeReves = self.provider.get_sigma8_z(self.z_winCompleto)/sigma8z0\n",
    "        De = DeReves[::-1]\n",
    "        \n",
    "        def bJPAS(z):\n",
    "          return 0.53+0.289*(1+z)**2\n",
    "            \n",
    "        A = De*bJPAS(za)*sigma8z0\n",
    "        R = De*f*sigma8z0\n",
    "\n",
    "        # Photometric factor\n",
    "        DeltazJPAS = 0.00364236313918151\n",
    "        sigmar = DeltazJPAS*(1+self.z_winCompleto)/H\n",
    "\n",
    "\n",
    "        # This is the matter power spectrum interpolator:\n",
    "        pk = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)    #P matter is obtained here\n",
    "        #pk_delta = pk.P(ks,self.z_winExtended)\n",
    "        #print(self.z_winExtended,pk.P(ks,hJPAS**3*self.z_winExtended[1]),'pruebaprint')\n",
    "        #print(pk.P(ks,self.z_winCompleto[2]), 'carlitos')\n",
    "        #print(pk.P(ks,self.z_winCompleto[2]), 'carlitos')\n",
    "        \n",
    "        #pk_delta = pk.P(ks,self.z_winCompleto)         # pk_delta is Pk evaluated at ks and zs\n",
    "        #print(ks,'carlitos')\n",
    "        #ca = self.provider.get_Pk_interpolator(self.z_winCompleto, ks[-1], nonlinear=False)\n",
    "        #plt.plot(ks, hJPAS**3*pk.P(ks,self.z_winExtended[1]), label='Pk_interpolator') \n",
    "        #plt.xlabel('k [1/Mpc]')\n",
    "        #plt.ylabel('Pm [Mpc^3]')\n",
    "        #plt.savefig('Pm_interpolator.png') \n",
    "        #plt.show() \n",
    "\n",
    "        \n",
    "        # Fingers of God effect\n",
    "        sigmap = (   1/(6*np.pi**2)*(De[2]/1)**2*integrate.quad(lambda k: pk.P(k,self.z_winExtended[48]) , ks[0], ks[-1])[0]  )**0.5\n",
    "\n",
    "\n",
    "        \n",
    "        def FFog(mu,k):\n",
    "            return 1/(1+(f[2]*k*mu*sigmap)**2)\n",
    "\n",
    "        \n",
    "        # AP effect\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_winCompleto)*hJPAS;\n",
    "        DA = Xi/(1+self.z_winCompleto);\n",
    "        \n",
    "        FactorAP = DAFid**2*Ez[2]/( DA[2]**2*EzFid )\n",
    "\n",
    "        def Q(mu):\n",
    "            return ((Ez[2]**2*Xi[2]**2*mu**2-EzFid**2*XiFid**2*(mu**2-1))**0.5/(EzFid*Xi[2]))\n",
    " \n",
    "        def muObs(mu):\n",
    "            return mu*Ez[2]/(EzFid*Q(mu))\n",
    "           \n",
    "        def kObs(mu,k):\n",
    "            return Q(mu)*k \n",
    "\n",
    "        #P galaxy\n",
    "        def Pg(mu,k):\n",
    "            return FactorAP*FFog(muObs(mu),kObs(mu,k))*(A[2]+R[2]*muObs(mu)**2)**2 * pk.P(kObs(mu,k),self.z_winExtended[1])/sigma8z0**2 *np.exp(-(k*mu*sigmar[2])**2)\n",
    "\n",
    "        #Trapezoid rule with 2000 steps for computing the Pmonopole(k)\n",
    "        def Pgmonopole(k):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 1/2 * integrate.trapz(Pg(mu, k), mu)\n",
    "            \n",
    "        PgmonopoleValores = np.zeros(len(self.ks))\n",
    "\n",
    "        for i in range(0, len(ks)):\n",
    "             PgmonopoleValores[i] = Pgmonopole(ks[i])\n",
    "\n",
    "        \n",
    "        #Covariance\n",
    "        \n",
    "        #Densities are red from self.data['ndz].\n",
    "\n",
    "        #Definition of the volume (requires angular distance and za lower/upper bining)\n",
    "        #Area of the sky\n",
    "        fsky = 0.2575;\n",
    "\n",
    "        #Angular distance for z upper and lower bins. Not exactly equal to my previous example?\n",
    "\n",
    "        XiZaLower = self.provider.get_comoving_radial_distance(self.z_winCompleto[positions_Lower])*hJPAS\n",
    "        XiZaUpper = self.provider.get_comoving_radial_distance(self.z_winCompleto[positions_Upper])*hJPAS\n",
    "              \n",
    "        #Definition of the volume between redshift bins\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "\n",
    "        #Number of modes. It depends of ksup and kinf corresponding to kupper y klower\n",
    "        def Nk(ksup,kinf):\n",
    "            return Vol[0] * (4*np.pi/3*(ksup**3-kinf**3))/((2*np.pi)**3)\n",
    "\n",
    "        #Nk evaluated for each of our k-bins\n",
    "        NkEvaluado = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "            NkEvaluado[i] = Nk(KArrayUpper[i],KArrayLower[i])\n",
    "\n",
    "            \n",
    "        #Covariance Cov definition\n",
    "        def Cov(k,k1,k2):\n",
    "            return 2 * (Pgmonopole(k) + 1/self.data['ndz'][0])**2 / Nk(k1,k2)\n",
    "    \n",
    "        #Cov evaluated at our k array\n",
    "        CovEvaluado = 2 *(PgmonopoleValores + 1/self.data['ndz'][0])**2 / NkEvaluado\n",
    "\n",
    "        #We return the value of the monopole at our k-array and of the Covariance Matrix at the same array\n",
    "        return PgmonopoleValores, CovEvaluado\n",
    "\n",
    "\n",
    "    #Likelihood calculation\n",
    "    \n",
    "    def logp(self, **params_values):       \n",
    "        \n",
    "        Pkprueba = self.monopole(**params_values)[0]    #Del anterior código. ¿Debo llamar al monopolo así o con PgmonopoleValores[i]?\n",
    "        \n",
    "        #For allocating the monopole values and cov valued\n",
    "\n",
    "        PMonopoleBineado = np.zeros((7, len(self.ks)))\n",
    "        CovBineado = np.zeros((7, len(self.ks)))\n",
    "\n",
    "        \n",
    "        PMonopoleBineado[0, :len(self.ks)],CovBineado[0, :len(self.ks)] = self.monopole(**params_values)\n",
    "        \n",
    "        \n",
    "        #Likelihood is constructed, with j being the z-array value, and i the k-array value.\n",
    "        #Now we work with just j=0, corresponding to the first z-bin 1.7\n",
    "\n",
    "        #Likelihood similar to an chi^2. Factor of log cov?\n",
    "        def lnlikeSinSumar(j,i):\n",
    "            return (self.monopole(**params_values)[0][i]-data['pkz'][0][i])**2 * 1/CovBineado[j][i]\n",
    "            #return (self.monopole(**params_values)[0][i]-data['pkz'][0][i])**2 * 1/CovBineado[j][i] + np.log(CovBineado[j][i])\n",
    "            # return(PgBineado[j][i]-data['pkz'][0][i])**2 * 1/CovBineado[j][i] + np.log(CovBineado[j][i])\n",
    "\n",
    "        #Indices in which we sum over the likelihood values. We use all of them\n",
    "        IndicesLikelihood = np.arange(0,len(self.ks),1)\n",
    "\n",
    "        #Final likelihood value\n",
    "        lnlike = np.sum(lnlikeSinSumar(0,IndicesLikelihood))\n",
    "        \n",
    "        return lnlike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input given to Cobaya.\n",
    "\n",
    "# We define the dictionary 'info' including all our information, including the likelihood, theory (with the monopole)\n",
    "# and the priors\n",
    "\n",
    "info = {'debug': False,                        #Allow to debug\n",
    "        'likelihood': {'jpass': Pklike},      #Link likelihood (nombre jpass) with the previously defined class?\n",
    "        'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "                   'my_pk': NodesInPrimordialPk},      #Theory class, with the name \"my_pk\".\n",
    "       'params': {\n",
    "           \n",
    "        # Fixed cosmological parameters\n",
    "        'tau': 0.06, 'mnu': 0.00, 'nnu': 3.046, 'k1': 0.02, 'k2': 0.45,\n",
    "        #'P1': 2.2e-9, 'P2': 2.0e-9, 'ombh2': OmegabJPASh2Fid, 'omch2': OmegaCDMJPASFid, 'H0': hJPASFid*100}\n",
    "           \n",
    "        # Parameters of the nodes, with flat priors\n",
    "        'P1': {'prior': {'min': 1e-10, 'max': 5.6e-9}, 'latex': 'P_1'},\n",
    "        'P2': {'prior': {'min': 1e-10, 'max': 5.6e-9}, 'latex': 'P_2'},\n",
    "           \n",
    "        # Cosmological parameters to be sampled. Loc y scale are the mean value and the st deviation in a guassian prior\n",
    "        'ombh2': {'prior': {'dist': 'norm', 'loc': OmegabJPASh2Fid, 'scale': 0.00015}, 'latex': 'Omega_bh^2'},\n",
    "        'omch2': {'prior': {'dist': 'norm', 'loc': OmegaCDMJPASh2Fid, 'scale': 0.0012}, 'latex': 'Omega_ch^2'},\n",
    "        'H0': {'prior': {'dist': 'norm', 'loc': hJPASFid*100, 'scale': 0.54}, 'latex': 'H_0'}},\n",
    "\n",
    "        \"sampler\": {\"polychord\": None}}\n",
    "        #'sampler': {\n",
    "            #'evaluate': {\n",
    "                #'override': {\n",
    "                   #'P1': 2.2e-9, 'P2': 2.0e-9, 'ombh2': OmegabJPASh2Fid, 'omch2': OmegaCDMJPASFid, 'H0': hJPASFid*100}}}\n",
    "       #}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] *WARNING* Ignored blocks/options: ['sampler']\n",
      "[camb] `camb` module loaded successfully from /Users/guillermo/Desktop/code/CAMB/camb\n"
     ]
    }
   ],
   "source": [
    "# Let's reproduce the same matter power spectrum as the one by single camb through the cobaya interface\n",
    "\n",
    "from cobaya.model import get_model     \n",
    "model = get_model(info)          #A model is constructed with the 'info' dictionary\n",
    "\n",
    "fixed_values = {'tau': 0.06, 'mnu': 0.00, 'nnu': 3.046, 'k1': 0.02, 'k2': 0.45,\n",
    "    'P1': 2.12e-9, 'P2': 1.89e-9, 'H0': 67.38, 'ombh2': OmegabJPASh2Fid,\n",
    "    'omch2': OmegaCDMJPASh2Fid}\n",
    "\n",
    "model.logposterior(fixed_values)          #Esto?\n",
    "\n",
    "camb_results = model.provider.get_CAMBdata();  #Esto?\n",
    "\n",
    "#pk = model.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False) #Y esto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogPosterior(logpost=152871.43629700085, logpriors=[51.42602914422573], loglikes=array([152820.01026786]), derived=[], finite=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logposterior(fixed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[camb] `camb` module loaded successfully from /Users/guillermo/Desktop/code/CAMB/camb\n",
      "[polychord] `pypolychord` module loaded successfully from /Users/guillermo/Desktop/code/code/PolyChordLite/build/lib.macosx-10.9-universal2-3.9/pypolychord\n",
      "[polychord] Storing raw PolyChord output in '/var/folders/1h/0trg724n2fg2pn5j02gypgzc0000gn/T/polychord_raw'.\n",
      "[model] Measuring speeds... (this may take a few seconds)\n",
      "[model] Setting measured speeds (per sec): {jpass: 3.38, camb.transfers: 3.12, camb: 534.0, my_pk: 5910.0}\n",
      "[polychord] Parameter blocks and their oversampling factors:\n",
      "[polychord] * 1 : ['ombh2', 'omch2', 'H0']\n",
      "[polychord] * 1 : ['P1', 'P2']\n",
      "[prior] *WARNING* There are unbounded parameters (['ombh2', 'omch2', 'H0']). Prior bounds are given at 0.9999995 confidence level. Beware of likelihood modes at the edge of the prior\n",
      "[polychord] Calling PolyChord...\n",
      "PolyChord: MPI is already initilised, not initialising, and will not finalize\n",
      "\n",
      "PolyChord: Next Generation Nested Sampling\n",
      "copyright: Will Handley, Mike Hobson & Anthony Lasenby\n",
      "  version: 1.20.1\n",
      "  release: 1st June 2021\n",
      "    email: wh260@mrao.cam.ac.uk\n",
      "\n",
      "Run Settings\n",
      "nlive    :     125\n",
      "nDims    :       5\n",
      "nDerived :       2\n",
      "Doing Clustering\n",
      "Synchronous parallelisation\n",
      "Generating equally weighted posteriors\n",
      "Generating weighted posteriors\n",
      "Clustering on posteriors\n",
      "Writing a resume file to /var/folders/1h/0trg724n2fg2pn5j02gypgzc0000gn/T/polychord_raw/4c05c8.resume\n",
      "\n",
      "generating live points\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cobaya import run\n",
    "updated_info, sampler = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
