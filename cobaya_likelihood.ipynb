{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to be loaded. Probably there are duplicated or missing ones\n",
    "import cobaya\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "import camb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmological parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosmological constants\n",
    "c = 2.99792458E5;   HJPAS = 1/(c/100);\n",
    "\n",
    "#Parameteres that won't be sampled\n",
    "gamma = 0.545; OmegakJPAS = 0; AsJPAS = 2.09052E-9; nsJPAS = 0.9626; \n",
    "\n",
    "#Direct cosmological parameters of the fiducial cosmology\n",
    "hJPASFid = 0.6736; OmegabJPASh2Fid = 0.02237; OmegaCDMJPASh2Fid = 0.1200; \n",
    "OmegamJPASFid = 0.3153;\n",
    "\n",
    "#Indirect cosmological parameters of the fiducial cosmology\n",
    "OmegabJPASFid = OmegabJPASh2Fid/hJPASFid**2; OmegaCDMJPASFid = OmegaCDMJPASh2Fid/hJPASFid**2;\n",
    "OmegaLJPASFid = 1 - OmegamJPASFid;\n",
    "\n",
    "#Cosmological parameters outside the fiducial cosmology\n",
    "hJPAS = hJPASFid + hJPASFid/100;\n",
    "OmegabJPASh2 = OmegabJPASh2Fid + OmegabJPASh2Fid/100;\n",
    "OmegaCDMJPASh2 = OmegaCDMJPASh2Fid + OmegaCDMJPASh2Fid/100; \n",
    "OmegamJPAS = OmegamJPASFid + OmegamJPASFid/100;\n",
    "\n",
    "#Indirect cosmological parameters outside the fiducial\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2; OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;\n",
    "OmegaLJPAS = 1 - OmegamJPAS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiducial cosmology functions and constants\n",
    "OmegamFid = 0.31417\n",
    "\n",
    "#At z=1.7 (first bin)\n",
    "EzFid = 2.6210003\n",
    "XiFid = 3263.07985798\n",
    "DaFid = 1208.54809555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k and z binning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays limits and steps. In h units\n",
    "kminKArrayCompleto = 0.001;   kmaxKArrayCompleto = 2.4900;  pasoKArrayCompleto = 0.025;\n",
    "zmin = 1.7;   zmax = 2.9;   pasoz = 0.2;\n",
    "\n",
    "#k binning, complete and in a reduced scaleset\n",
    "KArrayCompleto = np.exp(np.arange(math.log(kminKArrayCompleto), math.log(kmaxKArrayCompleto), pasoKArrayCompleto) )\n",
    "KArray = KArrayCompleto[range(121,246)]\n",
    "\n",
    "#k binning on lower and upper limits\n",
    "KArrayUpper = np.zeros(len(KArray)); KArrayLower = np.zeros(len(KArray));\n",
    "\n",
    "for i in range(0, len(KArray)-1):\n",
    "    KArrayUpper[i] = KArray[i] + (KArray[i+1]-KArray[i])/2;   KArrayLower[i] = KArray[i] - (KArray[i+1]-KArray[i])/2;\n",
    "\n",
    "KArrayUpper[-1] = KArrayUpper[-2];  KArrayLower[-1] = KArrayLower[-2];\n",
    "\n",
    "\n",
    "#z binning\n",
    "\n",
    "#Original one\n",
    "zaAntes = np.arange(zmin-0.1, zmax+pasoz/2, pasoz)\n",
    "\n",
    "#Including z=0\n",
    "zaAdicional = np.array([0])\n",
    "\n",
    "#Binning including all lower and upper z-bins limits\n",
    "zaConBines = np.arange(zmin-pasoz/2, zmax+0.01+pasoz/2, pasoz/2)\n",
    "\n",
    "#z binning\n",
    "za = np.concatenate((zaAdicional,zaConBines))\n",
    "\n",
    "#Positions of upper and lower limits of the z-bins in the za array\n",
    "positions_Upper = [3, 5, 7, 9, 11, 13, 15]\n",
    "positions_Lower = [1, 3, 5, 7, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(k) data and densities reading #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pkz', 'ndz'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a class to read the simulated data specifying the path as input\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    Simulated_pk_filename = path_to_data+'FicticioHighZArrayEnK.dat'\n",
    "    Simulated_densities = path_to_data+'DensityHighZ.dat'\n",
    "\n",
    "    data['pkz'] = np.zeros((len(zaAntes), len(KArray)))\n",
    "    data['ndz'] = np.zeros(len(zaAntes))\n",
    "  \n",
    "    with open(Simulated_pk_filename) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['pkz'][0][i] = float(line[2])\n",
    "            data['pkz'][1][i] = float(line[3])\n",
    "            data['pkz'][2][i] = float(line[4])\n",
    "            data['pkz'][3][i] = float(line[5])\n",
    "            data['pkz'][4][i] = float(line[6])\n",
    "            data['pkz'][5][i] = float(line[7])\n",
    "            data['pkz'][6][i] = float(line[8])\n",
    "\n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(zaAntes)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Read data is converted in the dictionary 'data'\n",
    "data = read_data('/Users/guillermo/Desktop/')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMB settings and results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    }
   ],
   "source": [
    "# Let's try to obtain a PPS and Pm with nodes using CAMB\n",
    "\n",
    "#Nodes value test\n",
    "nodes_log_k = [np.log(KArray[0]), np.log(KArray[-1])]\n",
    "nodes_log_PPS = [2.3, 3.1]\n",
    "\n",
    "#Undo the logs\n",
    "nodes_k = np.exp(nodes_log_k)\n",
    "nodes_PPS = np.exp(nodes_log_PPS)*1e-10\n",
    "\n",
    "#Node interpolation. With just 2, kind always linear\n",
    "func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  #This command interpolates among columns\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "\n",
    "\n",
    "#Parameter set 'pars' for CAMB, with its cosmology, a modified PPS and a P(m) including the nodes\n",
    "from camb import model\n",
    "\n",
    "pars = camb.CAMBparams()\n",
    "pars.InitPower = camb.initialpower.SplinedInitialPower()\n",
    "pars.set_cosmology(H0=hJPAS*100, ombh2=OmegabJPASh2, omch2=OmegaCDMJPASh2, mnu=0.0, omk=OmegakJPAS, tau=0.06)\n",
    "pars.InitPower.set_scalar_log_regular(KArray[0], KArray[-1], func(KArray))\n",
    "pars.set_matter_power(redshifts=za, kmax=KArrayCompleto[-1])\n",
    "pars.NonLinear = model.NonLinear_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMB matter power spectrum Pm(k) with the nodes methodology included.\n",
    "\n",
    "results = camb.get_results(pars) #Resultados de CAMB\n",
    "kh, z, pk = results.get_matter_power_spectrum(minkh=KArrayCompleto[0], maxkh=KArrayCompleto[-1], npoints = len(KArrayCompleto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to interface with Cobaya #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If previous is OK, now the classes to interface with Cobaya are created.\n",
    "\n",
    "#A cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes are created\n",
    "\n",
    "#Needed packages\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class of the theory, with the PPS modification including the nodes\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Initialize self with the k-array\n",
    "        self.ks = KArray\n",
    "\n",
    "    #It seems that in here we allocate the values of the parameters to be sampled and definme their names\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict):\n",
    "        \n",
    "        pivot_scalar = 0.05   #k pivot value\n",
    "        \n",
    "        nodes_k = [params_values_dict['k1'], params_values_dict['k2']] \n",
    "        nodes_PPS = [params_values_dict['P1'], params_values_dict['P2']] \n",
    "        \n",
    "        #nodes_k and nodes_PPS are interpolated\n",
    "        Pk_func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  # interpolate along columns\n",
    "                bounds_error=False,\n",
    "                kind='linear',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "        \n",
    "        #The PPS(k) is evaluated at our array of k\n",
    "        state['primordial_scalar_pk'] = {'kmin': self.ks[0], 'kmax': self.ks[-1],\n",
    "                                         'Pk': Pk_func(self.ks), 'log_regular': True}\n",
    "\n",
    "    #To be able to evaluate the PPS?\n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "   \n",
    "    #Function that returns the nodes parameters values\n",
    "    def get_can_support_params(self):\n",
    "        return ['k1', 'k2', 'P1', 'P2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class incorporating the monopole and the likelihood. \n",
    "\n",
    "\n",
    "class Pklike(Likelihood): #Class is defined\n",
    "    \n",
    "    def initialize(self):  \n",
    "\n",
    "        #Path in wich the data are. We call read_data with this path.\n",
    "        self.data = read_data('/Users/guillermo/Desktop/')\n",
    "\n",
    "        #Grid of z to be employed\n",
    "        self.z_win = zaAntes\n",
    "        self.z_winCompleto = za\n",
    "\n",
    "    \n",
    "    def get_requirements(self): #¿Por qué es necesario tener requisitos? ¿No puedo usar las funciones sin esto?\n",
    "        \n",
    "        return {'omegam': None,                 \n",
    "                'Pk_interpolator': {'z': self.z_winCompleto, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_winCompleto},\n",
    "                'angular_diameter_distance': {'z': self.z_winCompleto},\n",
    "                'Hubble': {'z': self.z_winCompleto, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_winCompleto},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    "\n",
    "   \n",
    "    #Definition of the monopole\n",
    "    \n",
    "    def monopole(self, **params_dic):\n",
    "\n",
    "        results = self.provider.get_CAMBdata()   #CAMB results in results\n",
    "             \n",
    "        # Esta parte quizás la puedo omitir\n",
    "        ks = KArray\n",
    "        pps = results.Params.scalar_power(ks)       \n",
    "        \n",
    "        # All functions and variables to compute the Kaiser model\n",
    "        Omegam = self.provider.get_param('omegam');  \n",
    "        Ez = np.sqrt( Omegam*(1+self.z_winCompleto)**3+(1-Omegam) ); \n",
    "        H = HJPAS * Ez\n",
    "        f = (Omegam*(1+self.z_winCompleto)**3*1/(Ez**2))**gamma\n",
    "        sigma8z0 = self.provider.get_sigma8_z(self.z_winCompleto[0])\n",
    "        DeReves = self.provider.get_sigmaR_z(8,self.z_winCompleto)/self.provider.get_sigmaR_z(8,self.z_winCompleto[0])\n",
    "        De = DeReves[::-1]\n",
    "        \n",
    "        def bJPAS(z):\n",
    "          return 0.53+0.289*(1+z)**2\n",
    "            \n",
    "        A = De*bJPAS(za)*sigma8z0\n",
    "        R = De*f*sigma8z0\n",
    "\n",
    "        # Photometric factor\n",
    "        DeltazJPAS = 0.00364236313918151\n",
    "        sigmar = DeltazJPAS*(1+self.z_winCompleto)/H\n",
    "\n",
    "        # This is the matter power spectrum interpolator:\n",
    "        pk = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)   #P matter is obtained here\n",
    "        pk_delta = pk.P(ks, self.z_winCompleto)         # pk_delta is Pk evaluated at ks and zs\n",
    "\n",
    "        \n",
    "        # Fingers of God effect\n",
    "        sigmap = (1/(6*np.pi**2)*(De/1)**2*integrate.quad(lambda k:  pk.P(k, self.z_winCompleto[2]) , ks[0], ks[-1])**0.5)\n",
    "\n",
    "        def FFoG(mu,k):\n",
    "            return 1/(1+(f[2]*k*mu*sigmap)**2)\n",
    "\n",
    "        # AP effect\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_winCompleto)*hJPAS;\n",
    "        DA = Xi/(1+self.z_winCompleto);\n",
    "        \n",
    "        FactorAP = DAFid**2*Ez[0]/( DA[0]**2*EzFid )\n",
    "\n",
    "        def Q(mu):\n",
    "            return ((Ez[2]**2*Xi[2]**2*mu**2-EzFid**2*XiFid**2*(mu**2-1))**0.5/(EzFid*Xi[2]))\n",
    " \n",
    "        def muObs(mu):\n",
    "            return mu*Ez[2]/(EzFid*Q(mu))\n",
    "           \n",
    "        def kObs(mu,k):\n",
    "            return Q(mu)*k \n",
    "\n",
    "        #P galaxy\n",
    "        def Pg(mu,k):\n",
    "            return FactorAP*FFog(muObs(mu),kObs(mu,k))*(A[2]+R[2]*muObs(mu)**2)**2 * PmatInterCAMB(kObs(mu,k))/sigma8z0**2 *np.exp(-(k*mu*sigmar[2])**2)\n",
    "\n",
    "        #Trapezoid rule with 2000 steps for computing the Pmonopole(k)\n",
    "        def Pgmonopole(k):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 1/2 * integrate.trapz(Pg(mu, k), mu)\n",
    "            \n",
    "        PgmonopoleValores = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "             PgmonopoleValores[i] = Pgmonopole(ks[i])\n",
    "\n",
    "        #Covariance\n",
    "        \n",
    "        #Densities are red from self.data['ndz].\n",
    "\n",
    "        #Definition of the volume (requires angular distance and za lower/upper bining)\n",
    "        #Area of the sky\n",
    "        fsky = 0.2575;\n",
    "\n",
    "        #Angular distance for z upper and lower bins:\n",
    "\n",
    "        XiZaLower = self.provider.get_comoving_radial_distance(self.z_winCompleto[positions_Lower])*hJPAS\n",
    "        XiZaUpper = self.provider.get_comoving_radial_distance(self.z_winCompleto[positions_Upper])*hJPAS\n",
    "\n",
    "        \n",
    "        #Definition of the volume between redshift bins\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "\n",
    "        #Number of modes. It depends of ksup and kinf corresponding to kupper y klower\n",
    "        def Nk(ksup,kinf):\n",
    "            return Vol[0] * (4*np.pi/3*(ksup**3-kinf**3))/((2*np.pi)**3)\n",
    "\n",
    "        #Nk evaluated for each of our k-bins\n",
    "        NkEvaluado = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "            NkEvaluado[i] = Nk(KArrayUpper[i],KArrayLower[i])\n",
    "\n",
    "        #Covariance Cov definition\n",
    "        def Cov(k,k1,k2):\n",
    "            return 2 * (Pgmonopole(k) + 1/self.data['ndz'][0])**2 / Nk(k1,k2)\n",
    "\n",
    "        #Cov evaluated at our k array\n",
    "        CovEvaluado = 2 *(PgmonopoleValores + 1/self.data['ndz'][0])**2 / NkEvaluado\n",
    "\n",
    "        #We return the value of the monopole at our k-array\n",
    "        return PgmonopoleValores\n",
    "\n",
    "\n",
    "    #Likelihood calculation\n",
    "    \n",
    "    def logp(self, **params_values):       \n",
    "        \n",
    "        Pk = self.monopole(**params_values)    #Del anterior código. ¿Debo llamar al monopolo así o con PgmonopoleValores[i]?\n",
    "        \n",
    "        #For allocating the monopole values\n",
    "        PMonopoleBineadoz1 = np.zeros(len(ks)); PMonopoleBineadoz2 = np.zeros(len(ks));\n",
    "        PMonopoleBineadoz3 = np.zeros(len(ks)); PMonopoleBineadoz4 = np.zeros(len(ks));\n",
    "        PMonopoleBineadoz5 = np.zeros(len(ks)); PMonopoleBineadoz6 = np.zeros(len(ks));\n",
    "        PMonopoleBineadoz7 = np.zeros(len(ks));\n",
    "\n",
    "        PMonopoleBineado = np.array([PMonopoleBineadoz1,PMonopoleBineadoz2,PMonopoleBineadoz3,PMonopoleBineadoz4,PMonopoleBineadoz5,PMonopoleBineadoz6,PMonopoleBineadoz7])\n",
    "\n",
    "        for i in range(0, len(ks)):\n",
    "            PMonopoleBineado[0][i] = PgmonopoleValores[i]\n",
    "\n",
    "        #For allocating the covariance values\n",
    "        CovBineadoz1 = np.zeros(len(ks)); CovBineadoz2 = np.zeros(len(ks));\n",
    "        CovBineadoz3 = np.zeros(len(ks)); CovBineadoz4 = np.zeros(len(ks));\n",
    "        CovBineadoz5 = np.zeros(len(ks)); CovBineadoz6 = np.zeros(len(ks));\n",
    "        CovBineadoz7 = np.zeros(len(ks));\n",
    "\n",
    "        CovBineado = np.array([CovBineadoz1,CovBineadoz2,CovBineadoz3,CovBineadoz4,CovBineadoz5,CovBineadoz6,CovBineadoz7])\n",
    "\n",
    "        for i in range(0, len(ks)):\n",
    "            CovBineado[0][i] = CovEvaluado[i]\n",
    "\n",
    "        #Likelihood is constructed, with j being the z-array value, and i the k-array value.\n",
    "        #Now we work with just j=0, corresponding to the first z-bin 1.7\n",
    "\n",
    "        #Likelihood similar to an chi^2. Factor of log cov?\n",
    "        def lnlikeSinSumar(j,i):\n",
    "            \n",
    "            return (self.monopole(**params_values)[i]-data['pkz'][0][i])**2 * 1/CovBineado[j][i] + np.log(CovBineado[j][i])\n",
    "            # return(PgBineado[j][i]-data['pkz'][0][i])**2 * 1/CovBineado[j][i] + np.log(CovBineado[j][i])\n",
    "\n",
    "            #Indices in which we sum over the likelihood values. We use all of them\n",
    "            IndicesLikelihood = np.arange(0,len(ks),1)\n",
    "\n",
    "            #Final likelihood value\n",
    "            lnlike = np.sum(lnlikeSinSumar(0,IndicesLikelihood))\n",
    "            return lnlike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input given to Cobaya.\n",
    "\n",
    "# We define the dictionary 'info' including all our information, including the likelihood, theory (with the monopole)\n",
    "# and the priors\n",
    "\n",
    "info = {'debug': True,                        #Allow to debug\n",
    "        'likelihood': {'jpass': Pklike},      #Link likelihood (nombre jpass) with the previously defined class?\n",
    "        'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "                   'my_pk': NodesInPrimordialPk},      #Theory class, with the name \"my_pk\".\n",
    "       'params': {\n",
    "           \n",
    "        # Fixed cosmological parameters\n",
    "        'tau': 0.06, 'mnu': 0.00, 'nnu': 3.046,\n",
    "           \n",
    "        # Parameters of the nodes, with flat priors\n",
    "        'P1': {'prior': {'min': 1e-10, 'max': 5.6e-9}, 'latex': 'P_1'},\n",
    "        'P2': {'prior': {'min': 1e-10, 'max': 5.6e-9}, 'latex': 'P_2'},\n",
    "           \n",
    "        # Cosmological parameters to be sampled. Loc y scale are the mean value and the st deviation in a guassian prior\n",
    "        'ombh2': {'prior': {'dist': 'norm', 'loc': OmegabJPASh2Fid, 'scale': 0.00015}, 'latex': 'Omega_bh^2'},\n",
    "        'omch2': {'prior': {'dist': 'norm', 'loc': OmegaCDMJPASFid, 'scale': 0.0012}, 'latex': 'Omega_ch^2'},\n",
    "        'H0': {'prior': {'dist': 'norm', 'loc': hJPASFid*100, 'scale': 0.54}, 'latex': 'H_0'}},\n",
    "       \n",
    "        'sampler': {\n",
    "            'evaluate': {\n",
    "                'override': {\n",
    "                   'P1': 2.2e-9, 'P2': 2.0e-9, 'ombh2': OmegabJPASh2Fid, 'omch2': OmegaCDMJPASFid, 'H0': hJPASFid*100}}}\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2024-01-19 12:53:52,844 [model] *WARNING* Ignored blocks/options: ['sampler']\n",
      " 2024-01-19 12:53:52,855 [model] Input info updated with defaults (dumped to YAML):\n",
      "theory:\n",
      "  camb:\n",
      "    version: null\n",
      "    path: null\n",
      "    speed: 0.3\n",
      "    stop_at_error: false\n",
      "    extra_args: null\n",
      "    ignore_obsolete: false\n",
      "    use_renames: false\n",
      "    external_primordial_pk: true\n",
      "    renames:\n",
      "      omegabh2: ombh2\n",
      "      omegach2: omch2\n",
      "      omegal: omega_de\n",
      "      omegak: omk\n",
      "      yhe: YHe\n",
      "      yheused: YHe\n",
      "      YpBBN: Y_p\n",
      "  my_pk:\n",
      "    speed: -1\n",
      "    stop_at_error: false\n",
      "    version: null\n",
      "    external: !!python/name:__main__.NodesInPrimordialPk ''\n",
      "likelihood:\n",
      "  jpass:\n",
      "    type: []\n",
      "    speed: -1\n",
      "    stop_at_error: false\n",
      "    version: null\n",
      "    external: !!python/name:__main__.Pklike ''\n",
      "params:\n",
      "  tau:\n",
      "    value: 0.06\n",
      "  mnu:\n",
      "    value: 0.0\n",
      "  nnu:\n",
      "    value: 3.046\n",
      "  P1:\n",
      "    prior:\n",
      "      min: 1.0e-10\n",
      "      max: 5.6e-09\n",
      "    latex: P_1\n",
      "  P2:\n",
      "    prior:\n",
      "      min: 1.0e-10\n",
      "      max: 5.6e-09\n",
      "    latex: P_2\n",
      "  ombh2:\n",
      "    prior:\n",
      "      dist: norm\n",
      "      loc: 0.02237\n",
      "      scale: 0.00015\n",
      "    latex: Omega_bh^2\n",
      "    renames:\n",
      "    - omegabh2\n",
      "  omch2:\n",
      "    prior:\n",
      "      dist: norm\n",
      "      loc: 0.26447041034523616\n",
      "      scale: 0.0012\n",
      "    latex: Omega_ch^2\n",
      "    renames:\n",
      "    - omegach2\n",
      "  H0:\n",
      "    prior:\n",
      "      dist: norm\n",
      "      loc: 67.36\n",
      "      scale: 0.54\n",
      "    latex: H_0\n",
      "debug: true\n",
      "\n",
      " 2024-01-19 12:53:52,891 [camb] Attempting import of Cobaya-installed version, but defaulting to global import if not found.\n",
      " 2024-01-19 12:53:52,893 [camb] No (compiled) installation of 'camb' at /Users/guillermo/Desktop/code/code/CAMB: Could not find compiled CAMB library camblib.so in /Users/guillermo/Desktop/code/code/CAMB.\n",
      " 2024-01-19 12:53:52,901 [camb] Defaulting to global import.\n",
      " 2024-01-19 12:53:52,910 [camb] `camb` module loaded successfully from /Users/guillermo/Desktop/code/CAMB/camb\n",
      " 2024-01-19 12:53:52,928 [model] Parameters were assigned as follows:\n",
      " 2024-01-19 12:53:52,933 [model] - jpass:\n",
      " 2024-01-19 12:53:52,936 [model]      Input:  []\n",
      " 2024-01-19 12:53:52,939 [model]      Output: []\n",
      " 2024-01-19 12:53:52,942 [model] - camb.transfers:\n",
      " 2024-01-19 12:53:52,946 [model]      Input:  ['tau', 'mnu', 'nnu', 'ombh2', 'omch2', 'H0']\n",
      " 2024-01-19 12:53:52,949 [model]      Output: []\n",
      " 2024-01-19 12:53:52,954 [model] - camb:\n",
      " 2024-01-19 12:53:52,957 [model]      Input:  []\n",
      " 2024-01-19 12:53:52,958 [model]      Output: []\n",
      " 2024-01-19 12:53:52,960 [model] - my_pk:\n",
      " 2024-01-19 12:53:52,963 [model]      Input:  ['P1', 'P2']\n",
      " 2024-01-19 12:53:52,968 [model]      Output: []\n",
      " 2024-01-19 12:53:52,989 [model] Components will be computed in the order:\n",
      " 2024-01-19 12:53:52,991 [model]  - [camb.transfers, my_pk, camb, jpass]\n",
      " 2024-01-19 12:53:52,994 [model] Requirements will be calculated by these components:\n",
      " 2024-01-19 12:53:52,998 [model] - omegam: camb\n",
      " 2024-01-19 12:53:53,002 [model] - Pk_interpolator: camb\n",
      " 2024-01-19 12:53:53,004 [model] - comoving_radial_distance: camb\n",
      " 2024-01-19 12:53:53,006 [model] - angular_diameter_distance: camb\n",
      " 2024-01-19 12:53:53,007 [model] - Hubble: camb\n",
      " 2024-01-19 12:53:53,008 [model] - sigma8_z: camb\n",
      " 2024-01-19 12:53:53,011 [model] - CAMBdata: camb\n",
      " 2024-01-19 12:53:53,014 [model] - CAMB_transfers: camb.transfers\n",
      " 2024-01-19 12:53:53,015 [model] - primordial_scalar_pk: my_pk\n",
      " 2024-01-19 12:53:53,018 [parameterization] *ERROR* The following expected sampled parameters (or their aliases) were not found : {'P1': [], 'ombh2': ['omegabh2'], 'P2': [], 'omch2': ['omegach2'], 'H0': []}\n"
     ]
    },
    {
     "ename": "LoggedError",
     "evalue": "The following expected sampled parameters (or their aliases) were not found : {'P1': [], 'ombh2': ['omegabh2'], 'P2': [], 'omch2': ['omegach2'], 'H0': []}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLoggedError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcobaya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model     \n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(info)          \u001b[38;5;66;03m#A model is constructed with the 'info' dictionary\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m#Esto?\u001b[39;00m\n\u001b[1;32m      8\u001b[0m camb_results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprovider\u001b[38;5;241m.\u001b[39mget_CAMBdata();  \u001b[38;5;66;03m#Esto?\u001b[39;00m\n\u001b[1;32m     10\u001b[0m pk \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprovider\u001b[38;5;241m.\u001b[39mget_Pk_interpolator((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_tot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_tot\u001b[39m\u001b[38;5;124m'\u001b[39m), nonlinear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#Y esto?\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cobaya/model.py:534\u001b[0m, in \u001b[0;36mModel.logposterior\u001b[0;34m(self, params_values, as_dict, make_finite, return_derived, cached, _no_check)\u001b[0m\n\u001b[1;32m    532\u001b[0m     params_values_array \u001b[38;5;241m=\u001b[39m params_values\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     params_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameterization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_sampled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     params_values_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_sampled_array(params_values)\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_debug():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cobaya/parameterization.py:326\u001b[0m, in \u001b[0;36mParameterization.check_sampled\u001b[0;34m(self, sampled_params)\u001b[0m\n\u001b[1;32m    324\u001b[0m     sampled_params \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sampled_params, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_sampled_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msampled_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sampled_params) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampled):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cobaya/parameterization.py:362\u001b[0m, in \u001b[0;36mParameterization.check_sampled_dict\u001b[0;34m(self, **sampled_params)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following expected sampled parameters \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwere not found : \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m                {p: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampled_renames[p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m not_found})\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LoggedError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog, \u001b[38;5;241m*\u001b[39mmsg)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Ignore fixed input parameters if they have the correct value\u001b[39;00m\n\u001b[1;32m    364\u001b[0m not_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sampled_params)\n",
      "\u001b[0;31mLoggedError\u001b[0m: The following expected sampled parameters (or their aliases) were not found : {'P1': [], 'ombh2': ['omegabh2'], 'P2': [], 'omch2': ['omegach2'], 'H0': []}"
     ]
    }
   ],
   "source": [
    "# Let's reproduce the same matter power spectrum as the one by single camb through the cobaya interface\n",
    "\n",
    "from cobaya.model import get_model     \n",
    "model = get_model(info)          #A model is constructed with the 'info' dictionary\n",
    "\n",
    "model.logposterior({})          #Esto?\n",
    "\n",
    "camb_results = model.provider.get_CAMBdata();  #Esto?\n",
    "\n",
    "pk = model.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False) #Y esto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobaya import run\n",
    "#updated_info, sampler = run(info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
