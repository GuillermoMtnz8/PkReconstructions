{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood nodal #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquetes a cargar. Puede que sobre alguno o haya alguno redundante\n",
    "import cobaya\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import erf\n",
    "from scipy.interpolate import CubicSpline\n",
    "import camb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constantes cosmológicas:\n",
    "c = 2.99792458E5;   HJPAS = 1/(c/100);\n",
    "\n",
    "#Parámetros que no se van a samplear:\n",
    "gamma = 0.545; OmegakJPAS = 0; AsJPAS = 2.09052E-9; nsJPAS = 0.9626; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros cosmológicos directos:\n",
    "hJPASFid = 0.6736; OmegabJPASh2Fid = 0.02237; OmegaCDMJPASh2Fid = 0.1200; \n",
    "OmegamJPASFid = 0.3153;\n",
    "\n",
    "#Parámetros cosmológicos indirectos:\n",
    "OmegabJPASFid = OmegabJPASh2Fid/hJPASFid**2; OmegaCDMJPASFid = OmegaCDMJPASh2Fid/hJPASFid**2;\n",
    "OmegaLJPASFid = 1 - OmegamJPASFid;\n",
    "\n",
    "#Parámetros cosmológicos fuera del fiducial:\n",
    "hJPAS = hJPASFid + hJPASFid/100;\n",
    "OmegabJPASh2 = OmegabJPASh2Fid + OmegabJPASh2Fid/100;\n",
    "OmegaCDMJPASh2 = OmegaCDMJPASh2Fid + OmegaCDMJPASh2Fid/100; \n",
    "OmegamJPAS = OmegamJPASFid + OmegamJPASFid/100;\n",
    "\n",
    "#Parámetros cosmológicos indirectos fuera del fiducial:\n",
    "OmegabJPAS = OmegabJPASh2/hJPAS**2; OmegaCDMJPAS = OmegaCDMJPASh2/hJPAS**2;\n",
    "OmegaLJPAS = 1 - OmegamJPAS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bineado de k y de z\n",
    "#Límites y pasos de los arrays. Escalas en unidades de h.\n",
    "kminKArrayCompleto = 0.001;   kmaxKArrayCompleto = 2.4900;  pasoKArrayCompleto = 0.025;\n",
    "zmin = 1.7;   zmax = 2.9;   pasoz = 0.2;\n",
    "\n",
    "#Bines de k, completos y reducidos\n",
    "KArrayCompleto = np.exp(np.arange(math.log(kminKArrayCompleto), math.log(kmaxKArrayCompleto), pasoKArrayCompleto) )\n",
    "KArray = KArrayCompleto[range(121,246)]\n",
    "\n",
    "#Bines de z:\n",
    "za = np.arange(zmin, zmax+pasoz/2, pasoz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to read the data\n",
    "def read_data(path_to_data):\n",
    "    data = {}\n",
    "\n",
    "    Simulated_pk_filename = path_to_data+'FicticioHighZArrayEnK.dat'\n",
    "    Simulated_densities = path_to_data+'DensityHighZ.dat'\n",
    "\n",
    "\n",
    "    data['pkz'] = np.zeros((len(za), len(KArray)))\n",
    "    data['ndz'] = np.zeros(len(za))\n",
    "  \n",
    "\n",
    "    with open(Simulated_pk_filename) as file:\n",
    "        for i in range(len(KArray)):\n",
    "            line = file.readline().split()\n",
    "            data['pkz'][0][i] = float(line[2])\n",
    "            data['pkz'][1][i] = float(line[3])\n",
    "            data['pkz'][2][i] = float(line[4])\n",
    "            data['pkz'][3][i] = float(line[5])\n",
    "            data['pkz'][4][i] = float(line[6])\n",
    "            data['pkz'][5][i] = float(line[7])\n",
    "            data['pkz'][6][i] = float(line[8])\n",
    "\n",
    "    with open(Simulated_densities) as file:\n",
    "        for i in range(len(za)):\n",
    "            line = file.readline().split()\n",
    "            data['ndz'][i] = float(line[1])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pkz', 'ndz'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aquí se da el string del path para ejecutar read_data\n",
    "# Read data as dictionary\n",
    "data = read_data('/Users/guillermo/Desktop/')\n",
    "# show data, we do not need Dz, fz, Haz, these are requested by camb\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class: <CAMBparams>\n",
       " WantCls = True\n",
       " WantTransfer = True\n",
       " WantScalars = True\n",
       " WantTensors = False\n",
       " WantVectors = False\n",
       " WantDerivedParameters = True\n",
       " Want_cl_2D_array = True\n",
       " Want_CMB = True\n",
       " Want_CMB_lensing = True\n",
       " DoLensing = True\n",
       " NonLinear = NonLinear_none\n",
       " Transfer: <TransferParams>\n",
       "   high_precision = True\n",
       "   accurate_massive_neutrinos = False\n",
       "   kmax = 2.44060197762477\n",
       "   k_per_logint = 0\n",
       "   PK_num_redshifts = 7\n",
       "   PK_redshifts = [2.8999999999999995, 2.6999999999999997, 2.5, 2.3, 2.0999999999999996, 1.9, 1.7]\n",
       " want_zstar = False\n",
       " want_zdrag = False\n",
       " min_l = 2\n",
       " max_l = 2500\n",
       " max_l_tensor = 600\n",
       " max_eta_k = 5000.0\n",
       " max_eta_k_tensor = 1200.0\n",
       " ombh2 = 0.022\n",
       " omch2 = 0.122\n",
       " omk = 0.0\n",
       " omnuh2 = 0.000644866570625114\n",
       " H0 = 67.5\n",
       " TCMB = 2.7255\n",
       " YHe = 0.24569492503497048\n",
       " num_nu_massless = 2.0293333333333337\n",
       " num_nu_massive = 1\n",
       " nu_mass_eigenstates = 1\n",
       " share_delta_neff = False\n",
       " nu_mass_degeneracies = [1.0146666666666666]\n",
       " nu_mass_fractions = [1.0]\n",
       " nu_mass_numbers = [1]\n",
       " InitPower: <SplinedInitialPower>\n",
       "   effective_ns_for_nonlinear = -1.0\n",
       " Recomb: <Recfast>\n",
       "   min_a_evolve_Tm = 0.0011098779505118728\n",
       "   RECFAST_fudge = 1.125\n",
       "   RECFAST_fudge_He = 0.86\n",
       "   RECFAST_Heswitch = 6\n",
       "   RECFAST_Hswitch = True\n",
       "   AGauss1 = -0.14\n",
       "   AGauss2 = 0.079\n",
       "   zGauss1 = 7.28\n",
       "   zGauss2 = 6.73\n",
       "   wGauss1 = 0.18\n",
       "   wGauss2 = 0.33\n",
       " Reion: <TanhReionization>\n",
       "   Reionization = True\n",
       "   use_optical_depth = True\n",
       "   redshift = 10.0\n",
       "   optical_depth = 0.06\n",
       "   fraction = -1.0\n",
       "   include_helium_fullreion = True\n",
       "   helium_redshift = 3.5\n",
       "   helium_delta_redshift = 0.4\n",
       "   helium_redshiftstart = 5.5\n",
       "   tau_solve_accuracy_boost = 1.0\n",
       "   timestep_boost = 1.0\n",
       "   max_redshift = 50.0\n",
       "   delta_redshift = 0.5\n",
       " DarkEnergy: <DarkEnergyFluid>\n",
       "   w = -1.0\n",
       "   wa = 0.0\n",
       "   cs2 = 1.0\n",
       "   use_tabulated_w = False\n",
       " NonLinearModel: <Halofit>\n",
       "   Min_kh_nonlinear = 0.005\n",
       "   halofit_version = mead2020\n",
       "   HMCode_A_baryon = 3.13\n",
       "   HMCode_eta_baryon = 0.603\n",
       "   HMCode_logT_AGN = 7.8\n",
       " Accuracy: <AccuracyParams>\n",
       "   AccuracyBoost = 1.0\n",
       "   lSampleBoost = 1.0\n",
       "   lAccuracyBoost = 1.0\n",
       "   AccuratePolarization = True\n",
       "   AccurateBB = False\n",
       "   AccurateReionization = True\n",
       "   TimeStepBoost = 1.0\n",
       "   BackgroundTimeStepBoost = 1.0\n",
       "   IntTolBoost = 1.0\n",
       "   SourcekAccuracyBoost = 1.0\n",
       "   IntkAccuracyBoost = 1.0\n",
       "   TransferkBoost = 1.0\n",
       "   NonFlatIntAccuracyBoost = 1.0\n",
       "   BessIntBoost = 1.0\n",
       "   LensingBoost = 1.0\n",
       "   NonlinSourceBoost = 1.0\n",
       "   BesselBoost = 1.0\n",
       "   LimberBoost = 1.0\n",
       "   SourceLimberBoost = 1.0\n",
       "   KmaxBoost = 1.0\n",
       "   neutrino_q_boost = 1.0\n",
       " SourceTerms: <SourceTermParams>\n",
       "   limber_windows = True\n",
       "   limber_phi_lmin = 100\n",
       "   counts_density = True\n",
       "   counts_redshift = True\n",
       "   counts_lensing = False\n",
       "   counts_velocity = True\n",
       "   counts_radial = False\n",
       "   counts_timedelay = True\n",
       "   counts_ISW = True\n",
       "   counts_potential = True\n",
       "   counts_evolve = False\n",
       "   line_phot_dipole = False\n",
       "   line_phot_quadrupole = False\n",
       "   line_basic = True\n",
       "   line_distortions = True\n",
       "   line_extra = False\n",
       "   line_reionization = False\n",
       "   use_21cm_mK = True\n",
       " z_outputs = []\n",
       " scalar_initial_condition = initial_adiabatic\n",
       " InitialConditionVector = []\n",
       " OutputNormalization = 1\n",
       " Alens = 1.0\n",
       " MassiveNuMethod = Nu_best\n",
       " DoLateRadTruncation = True\n",
       " Evolve_baryon_cs = False\n",
       " Evolve_delta_xe = False\n",
       " Evolve_delta_Ts = False\n",
       " Do21cm = False\n",
       " transfer_21cm_cl = False\n",
       " Log_lvalues = False\n",
       " use_cl_spline_template = True\n",
       " min_l_logl_sampling = 5000\n",
       " SourceWindows = []\n",
       " CustomSources: <CustomSources>\n",
       "   num_custom_sources = 0\n",
       "   c_source_func = None\n",
       "   custom_source_ell_scales = []\n",
       " "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to reproduce with simple CAMB the nodes, Fig 1 of the paper.\n",
    "\n",
    "#Se dan los valores de los nodos\n",
    "\n",
    "nodes_log_k = [-5, -3.3]\n",
    "nodes_log_PPS = [3.5, 3.7]\n",
    "\n",
    "#Se deshace la escala log\n",
    "nodes_k = np.exp(nodes_log_k)\n",
    "nodes_PPS =np.exp(nodes_log_PPS)*1e-10\n",
    "\n",
    "# Let's compare to scipy\n",
    "#Aquí se realiza algún tipo de interpolación\n",
    "func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  # interpolate along columns\n",
    "                bounds_error=False,\n",
    "                kind='quadratic',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "\n",
    "#Set up a new set of parameters for CAMB\n",
    "#Metemos en pars los parámetros de CAMB, y en la subcategoría de InitPower esos datos. \n",
    "pars = camb.CAMBparams()\n",
    "pars.InitPower = camb.initialpower.SplinedInitialPower()\n",
    "\n",
    "#This function sets up with one massive neutrino and helium set using BBN consistency\n",
    "#Aquí cambiamos los parámetros por defecto de CAMB por estos que nos interesan a nosotros\n",
    "pars.set_cosmology(H0=hJPAS*100, ombh2=OmegabJPASh2, omch2=OmegaCDMJPASh2, mnu=0.0, omk=OmegakJPAS, tau=0.06)\n",
    "\n",
    "#Aquí decimos que en esta subcategoría se incorporen los ks de los nodos con su interpolación\n",
    "#pars.InitPower.set_scalar_table(nodes_k, nodes_PPS)\n",
    "pars.InitPower.set_scalar_log_regular(KArray[0], KArray[-1], func(KArray))\n",
    "\n",
    "#Ahora damos los redshifts de nuestro catálogo con el kmax del mismo para el espectro de materia.\n",
    "pars.set_matter_power(redshifts=za, kmax=KArrayCompleto[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get camb results \n",
    "# Obtenemos los resultados de CAMB y los comparamos a nuestros nodos interpolados\n",
    "\n",
    "# Obtenemos los resultados de CAMB con todos los cambios que hemos hecho en 'pars':\n",
    "results = camb.get_results(pars)\n",
    "\n",
    "#Creamos los ejes x e y para representar. Array de ks, llamado 'k':\n",
    "kplot = 10**np.linspace(-5, 1, 500)\n",
    "\n",
    "#Valores del P(k) en ese array 'k':\n",
    "scalar_pk = pars.scalar_power(kplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7, 1.9, 2.0999999999999996, 2.3, 2.5, 2.6999999999999997, 2.8999999999999995]\n"
     ]
    }
   ],
   "source": [
    "from camb import model #Se importa un modelo dentro de CAMB?\n",
    "\n",
    "#Linear spectra\n",
    "pars.NonLinear = model.NonLinear_none #Esto pone las no-linearidades a 0\n",
    "results = camb.get_results(pars) \n",
    "\n",
    "#Se da valor a estas variables desde el P materia(k) de CAMB, especificando nuestras escalas extremas y el número de puntos\n",
    "#kh son las ks, pk el valor del Pmateria(k)\n",
    "kh, z, pk = results.get_matter_power_spectrum(minkh=KArrayCompleto[0], maxkh=KArrayCompleto[-1], npoints = len(KArrayCompleto))\n",
    "\n",
    "#Lo mismo con sigma8 para cada bin de z\n",
    "s8 = np.array(results.get_sigma8())\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume this method above is ok, so I will now create the classes to interface with Cobaya\n",
    "# I will create a cobaya theory NodesInPrimordialPk and a cobaya external likelihood Pklike classes\n",
    "\n",
    "#Se crean las clases para interactuar con Cobaya: NodesInPrimordialPk (teoría) y Pklike (likelihood)\n",
    "\n",
    "from cobaya.theory import Theory\n",
    "from cobaya.likelihood import Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase con la teoría, es decir, con la modificación del Primordial para incluir nuestros nodos\n",
    "class NodesInPrimordialPk(Theory):\n",
    "\n",
    "    def initialize(self): #Creamos una función que devolverá self. Ahí metemos unos ks.\n",
    "        # need to provide valid results at wide k range, any that might be used, please change accordantly\n",
    "        self.ks = KArray\n",
    "\n",
    "    def calculate(self, state, want_derived=True, **params_values_dict): #Esta función hace....\n",
    "        pivot_scalar = 0.05 #please change if you need\n",
    "        #Ahora metemos en k1, pk1... los valores de los nodos anteriormente fijados\n",
    "        nodes_k = [params_values_dict['k1'], params_values_dict['k2']]\n",
    "        nodes_PPS = [params_values_dict['pk1'], params_values_dict['pk2']]\n",
    "        \n",
    "        #Se interpolan estos nodos.\n",
    "        Pk_func = interp1d(nodes_k, nodes_PPS,\n",
    "                axis=0,  # interpolate along columns\n",
    "                bounds_error=False,\n",
    "                kind='quadratic',\n",
    "                fill_value=(nodes_PPS[0], nodes_PPS[-1]))\n",
    "        \n",
    "        #Parece que aquí definimos la variable state, en la que construimos el P(k) en todas las escalas\n",
    "        state['primordial_scalar_pk'] = {'kmin': self.ks[0], 'kmax': self.ks[-1],\n",
    "                                         'Pk': Pk_func(self.ks), 'log_regular': True}\n",
    "\n",
    "    #No entiendo para que sirven estas dos funciones:\n",
    "    def get_primordial_scalar_pk(self):\n",
    "        return self.current_state['primordial_scalar_pk']\n",
    "   \n",
    "    #Parece que aquí hay que indicar qué parámetros nodales usamos\n",
    "    def get_can_support_params(self):\n",
    "        # Please, define here as many node params you like\n",
    "        return ['k1', 'k2', 'pk1', 'pk2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase con el likelihood. Aquí tendremos que introducir nuestro modelo y el cálculo del likelihood\n",
    "\n",
    "class Pklike(Likelihood): #Se define la clase.\n",
    "    \n",
    "    def initialize(self):  # Función initialize, que crea un bineado de redshift basado en read data\n",
    "\n",
    "        # Se leen los datos de read_data, como arriba\n",
    "        # Plese, be aware that you need to change the path\n",
    "        self.data = read_data('/Users/guillermo/Desktop/')\n",
    "\n",
    "        # Se da un grid de zs con extremos en nuestros bines y 150 pasos\n",
    "        # If you need some quantities at z = 0 you need to have z_win also at zero, please change accordantly\n",
    "        self.z_win = za\n",
    "\n",
    "   \n",
    "        # No entiendo para qué sirve esta función. Parece que evalua funciones comológicas en nuestro bineado de z z_win\n",
    "    \n",
    "    def get_requirements(self):\n",
    "        \n",
    "        return {'omegam': None,                 #¿Por qué incluir valores en los que no se evalúa nada en z_win?\n",
    "                'Pk_interpolator': {'z': self.z_win, 'k_max': 10, 'nonlinear': False, 'vars_pairs': ([['delta_tot', 'delta_tot']])},\n",
    "                'comoving_radial_distance': {'z': self.z_win},\n",
    "                'angular_diameter_distance': {'z': self.z_win},\n",
    "                'Hubble': {'z': self.z_win, 'units': 'km/s/Mpc'},\n",
    "                'sigma8_z': {'z': self.z_win},\n",
    "                 #'fsigma8': {'z': self.z_win, 'units': None},\n",
    "                'CAMBdata': None}\n",
    "\n",
    "    # Esta función parece definir el monopolo:\n",
    "    \n",
    "    def monopole(self, **params_dic):\n",
    "\n",
    "        results = self.provider.get_CAMBdata()   #Parece que esto lee los datos de CAMB\n",
    "        \n",
    "        #Aquí defino el bineado en k\n",
    "        kminKArrayCompleto = 0.001;   kmaxKArrayCompleto = 2.4900;  pasoKArrayCompleto = 0.025;\n",
    "        KArrayCompleto = np.exp( np.arange(math.log(kminKArrayCompleto), math.log(kmaxKArrayCompleto), pasoKArrayCompleto) )\n",
    "        KArray = KArrayCompleto[range(121,246)]\n",
    "        \n",
    "        # Aquí se puede acceder al PPS\n",
    "        ks = KArray\n",
    "        pps = results.Params.scalar_power(ks)       \n",
    "        \n",
    "        #Aquí creamos todas las funciones y variables necesarias para generar el P Kaiser.\n",
    "        Omegam = self.provider.get_Omega('baryon')+self.provider.get_Omega('cdm')\n",
    "        OmegamFid = self.providerFid.get_Omega('baryon')+self.providerFid.get_Omega('cdm')\n",
    "        Ez = np.sqrt( Omegam*(1+self.z_win)**3+(1-Omegam) );    EzFid = np.sqrt( OmegamFid*(1+self.z_win)**3+(1-OmegamFid) )\n",
    "        H = HJPAS * Ez\n",
    "        f = (Omegam*(1+self.z_win)**3*1/(Ez**2))**gamma\n",
    "        sigma8z0 = self.providerz0.get_sigma8_z(self.z_winz0)\n",
    "        DeReves = self.provider.get_sigmaR_z(8,self.z_win)/self.providerz0.get_sigmaR_z(8,self.z_winz0)\n",
    "        De = DeReves[::-1]\n",
    "        def bJPAS(z):\n",
    "          return 0.53+0.289*(1+z)**2\n",
    "        A = De*bJPAS(za)*sigma8z0\n",
    "        R = De*f*sigma8z0\n",
    "\n",
    "        #Fotometría\n",
    "        DeltazJPAS = 0.00364236313918151\n",
    "        sigmar = DeltazJPAS*(1+self.z_win)/H\n",
    "\n",
    "        # This is the matter power spectrum interpolator:\n",
    "        pk = self.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)   #Parece que aquí se obtiene el Pmateria\n",
    "        pk_delta = pk.P(ks, self.z_win)         # pk_delta is an array de pmateria evaluado en ks and zs\n",
    "\n",
    "        \n",
    "        #Fingers of God\n",
    "        sigmap = (1/(6*np.pi**2)*(De/1)**2*integrate.quad(lambda k:  pk.P(k, self.z_win[0]) , ks[0], ks[len(ks)-1])[0])**0.5\n",
    "        def FFog(mu,k):\n",
    "            return 1/(1+(f[0]*k*mu*sigmap[0])**2)\n",
    "\n",
    "        \n",
    "        #Efecto AP\n",
    "        Xi = self.provider.get_comoving_radial_distance(self.z_win)*hJPAS;   XiFid = self.providerFid.get_comoving_radial_distance(self.z_win)*hJPAS;\n",
    "        DA = Xi/(1+self.z_win);   DAFid = XiFid/(1+self.z_win)\n",
    "        FactorAP = DAFid**2*Ez/( DA**2*EzFid )\n",
    "\n",
    "        def Q(mu):\n",
    "            return ((Ez[0]**2*Xi[0]**2*mu**2-EzFid[0]**2*XiFid[0]**2*(mu**2-1))**0.5/(EzFid[0]*Xi[0]))\n",
    "            \n",
    "        def muObs(mu):\n",
    "            return mu*Ez[0]/(EzFid[0]*Q(mu))\n",
    "           \n",
    "        def kObs(mu,k):\n",
    "            return Q(mu)*k \n",
    "\n",
    "        #P de galaxias final\n",
    "        def Pg(mu,k):\n",
    "            return FactorAP[0]*FFog(muObs(mu),kObs(mu,k))*(A[0]+R[0]*muObs(mu)**2)**2 * PmatInterCAMB(kObs(mu,k))/sigma8z0**2 *np.exp(-(k*mu*sigmar[0])**2)\n",
    "\n",
    "        #Se usa la regla del trapecio con 2000 pasos\n",
    "        def Pgmonopole(k):\n",
    "            mu = np.arange(-1, 1, 1/1000)\n",
    "            return 1/2 * integrate.trapz(Pg(mu, k), mu)\n",
    "            \n",
    "        PgmonopoleValores = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "             PgmonopoleValores[i] = Pgmonopole(ks[i])\n",
    "\n",
    "        #Covarianza\n",
    "        \n",
    "        #Importación y lectura de las densidades\n",
    "        ImportacionDensityHighZ = [i.strip().split() for i in open(\"/Users/guillermo/Desktop/DensityHighZ.dat\").readlines()]\n",
    "\n",
    "        DensityHighZ = np.zeros(len(ImportacionDensityHighZ));\n",
    "\n",
    "        for i in range(0, len(ImportacionDensityHighZ)):\n",
    "          DensityHighZ[i] = ImportacionDensityHighZ[i][1]\n",
    "\n",
    "        #Definición del volumen (requiere distancia angular con unidades y binear en zupper y zlower)\n",
    "        #Área del cielo\n",
    "        fsky = 0.2575;\n",
    "\n",
    "        #Bines de z por arriba y por abajo:\n",
    "        z_win_upper = self.z_win+(self.z_win[[1]]-self.z_win[[0]])/2;    z_win_lower = self.z_win-(self.z_win[[1]]-self.z_win[[0]])/2;\n",
    "\n",
    "        #Distancia angular para los bines z upper y lower:\n",
    "        XiZaLower = resultszlower.comoving_radial_distance(z_win_lower)*hJPAS\n",
    "        XiZaUpper = resultszupper.comoving_radial_distance(z_win_upper)*hJPAS\n",
    "\n",
    "        #Definición de volumen:\n",
    "        Vol = 4*np.pi*fsky/3*(XiZaUpper**3-XiZaLower**3)\n",
    "\n",
    "        #Definición del número de modos (requiere arrays en kupper y klower):\n",
    "\n",
    "        #Bines de k por arriba y por abajo\n",
    "        KArrayUpper = np.zeros(len(ks)); KArrayLower = np.zeros(len(ks));\n",
    "\n",
    "        for i in range(0, len(ks)-1):\n",
    "            KArrayUpper[i] = ks[i] + (ks[i+1]-ks[i])/2;   KArrayLower[i] = ks[i] - (ks[i+1]-ks[i])/2;\n",
    "\n",
    "        KArrayUpper[-1] = KArrayUpper[-2];  KArrayLower[-1] = KArrayLower[-2];\n",
    "\n",
    "        #Número de modos. Depende de las variables k1 y k2, que debe corresponderse a kupper y klower\n",
    "        def Nk(k1,k2):\n",
    "            return Vol[0] * (4*np.pi/3*(k1**3-k2**3))/((2*np.pi)**3)\n",
    "\n",
    "        #Evaluamos Nk para cada valor de nuestro array de k\n",
    "        NkEvaluado = np.zeros(len(ks))\n",
    "        for i in range(0, len(ks)):\n",
    "            NkEvaluado[i] = Nk(KArrayUpper[i],KArrayLower[i])\n",
    "\n",
    "        #Definición de la covarianza\n",
    "\n",
    "        #Va a depender de k1 y k2. No me gusta mucho:\n",
    "        def Cov(k,k1,k2):\n",
    "            return 2 * (Pgmonopole(k) + 1/DensityHighZ[0])**2 / Nk(k1,k2)\n",
    "\n",
    "        #Evaluamos Cov para nuestros k\n",
    "        CovEvaluado = 2 *(PgmonopoleValores + 1/DensityHighZ[0])**2 / NkEvaluado\n",
    "\n",
    "        # Other cosmological quantities:\n",
    "        angular_distance = self.provider.get_angular_diameter_distance(self.z_win),\n",
    "        H = self.provider.get_Hubble(self.z_win),\n",
    "        fsigma8 = self.provider.get_fsigma8(self.z_win)\n",
    "        sigma8 = self.provider.get_sigma8_z(self.z_win)\n",
    "\n",
    "\n",
    "    # Esta función computa el loglikelihood\n",
    "    \n",
    "    def logp(self, **params_values):       \n",
    "        \n",
    "        # Calcular el monopolo:\n",
    "        \n",
    "        Pk = self.monopole(**params_values)    #Aquí se llama a la función monopolo\n",
    "        \n",
    "        # Calcular el loglikelihood\n",
    "\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you pass input to Cobaya\n",
    "# Keep in mind that right know the parameters are hardcoded (fijos), you need to change to priors\n",
    "# Diccionario que le pasamos a Cobaya, donde linkamos con nuestros códigos de teoróa y el likelihood.\n",
    "\n",
    "info = {'debug': True,                        #Esto permite obtener info de los errores\n",
    "        'likelihood': {'jpass': Pklike},      #Aquí se engancha el likelihood (nombre jpass) que hemos definido en la clase de arriba\n",
    "        'theory': {'camb': {\"external_primordial_pk\": True},\n",
    "                   'my_pk': NodesInPrimordialPk},      #Aquí le pasamos nuestra clase de teoría, con nombre \"my_pk\".\n",
    "       'params': {\n",
    "        # Parámetros cosmológicos fijados\n",
    "        'tau': 0.07, 'mnu': 0.00, 'nnu': 3.046,\n",
    "        # Parámetros nodales, flat priors\n",
    "        'P1': {'prior': {'min': 1e-9, 'max': 4e-9}, 'latex': 'P_1'},\n",
    "        'P2': {'prior': {'min': 1e-9, 'max': 4e-9}, 'latex': 'P_2'},\n",
    "        # Parámetros cosmológicos a samplear. Loc y scale son, en prior gaussiano, valor medio y desviación estandar.\n",
    "        'ombh2': {'prior': {'dist': 'norm', 'loc': OmegabJPASh2Fid, 'scale': 0.00015}, 'latex': 'Omega_bh^2'},\n",
    "        'omch2': {'prior': {'dist': 'norm', 'loc': OmegaCDMJPASFid, 'scale': 0.0012}, 'latex': 'Omega_ch^2'},\n",
    "        'H0': {'prior': {'dist': 'norm', 'loc': hJPASFid*100, 'scale': 0.54}, 'latex': 'H_0'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reproduce the same matter power spectrum as the one by single camb through the cobaya interface\n",
    "# Se reproduce el Pmateria construido por CAMB con la interfaz de Cobaya:\n",
    "\n",
    "from cobaya.model import get_model     \n",
    "model = get_model(info)          #Se construye un modelo con el diccionario info\n",
    "\n",
    "model.logposterior({}) \n",
    "\n",
    "camb_results = model.provider.get_CAMBdata();\n",
    "\n",
    "pk = model.provider.get_Pk_interpolator(('delta_tot', 'delta_tot'), nonlinear=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
